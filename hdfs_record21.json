{"version": 2, "width": 210, "height": 46, "timestamp": 1611304525, "env": {"SHELL": "/bin/bash", "TERM": "xterm"}}
[0.238738, "o", "\u001b]0;root@k8snode1:~/bigdata/docker-hadoop\u0007\u001b[?1034h[root@k8snode1 docker-hadoop]# "]
[2.042603, "o", "t"]
[2.253076, "o", "m"]
[2.405681, "o", "u"]
[2.515625, "o", "x"]
[2.704895, "o", " "]
[2.900186, "o", "a"]
[3.175116, "o", "\r\n"]
[3.181568, "o", "\u001b[?1049h\u001b(B\u001b[m\u001b[?1l\u001b>\u001b[H\u001b[2J\u001b[?12l\u001b[?25h\u001b[?1000l\u001b[?1006l\u001b[?1005l\u001b[c\u001b[>4;1m\u001b[?1004h\u001b]112\u0007\u001b[?25l\u001b[1;1H\u001b[34mnamenode           |\u001b[39m 2021-01-22 07:31:49,059 INFO BlockStateChange: BLOCK* processReport 0xa29bd426bdade10a: from storage DS-dd529312-0829-43f1-ad20-e527d1fff3d3 node DatanodeRegistration(172.31.0.4:9866, datanodeUuid=abae07ad-fd0d-426a-aef8-591ef6eca4d8, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-5d885f87-f12d-453a-bd74-f156a1b4b789;nsid=1924983753;c=1611284134883), blocks: 13, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 07:31:49,060 INFO datanode.DataNode: Successfully sent block report 0xa29bd426bdade10a,  containing 1 storage report(s), of which we sent 1. The reports had 13 total blocks and used 1 RPC(s). This took 2 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 07:31:49,060 INFO datanode.DataNode: "]
[3.181914, "o", "Got finalize command for block pool BP-51099006-172.31.0.6-1611284134883\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:35:52,675 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:35:52,922 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log aggregation status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 07:35:53,549 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610696153549 and earlier in 0.0 seconds\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 07:38:50,102 INFO datanode.DirectoryScanner: BlockPool BP-51099006-172.31.0.6-1611284134883 Total blocks: 13, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 07:40:53,550 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610696453550 and earlier in 0.0 seconds\u001b[K\r\n\u001b[36"]
[3.182006, "o", "m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:45:52,675 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:45:52,922 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log aggregation status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 07:45:53,553 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610696753550 and earlier in 0.003 seconds\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 07:50:53,554 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610697053553 and earlier in 0.001 seconds\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:55:52,676 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 07:55:52,922 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log aggregatio"]
[3.182033, "o", "n status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 07:55:53,554 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610697353554 and earlier in 0.0 seconds\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:00:53,555 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610697653554 and earlier in 0.001 seconds\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:05:52,676 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:05:52,922 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log aggregation status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:05:53,555 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610697953555 and earlier in 0.0 seconds\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:10:53,556 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610698253555 and ear"]
[3.182045, "o", "lier in 0.001 seconds\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:15:52,676 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:15:52,923 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log aggregation status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:15:53,558 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610698553556 and earlier in 0.002 seconds\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:20:53,559 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610698853558 and earlier in 0.001 seconds\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:25:37,150 INFO BlockStateChange: BLOCK* processReport 0xf6872ec5e8d6a4cc: from storage DS-17475022-fb5c-4b1d-809f-c824abfccb3f node DatanodeRegistration(172.31.0.2:9866, datanodeUuid=176e8c9b-db30-4d3a-98c2-ebd28e1c9ce3, infoPort=9864, infoSecurePort=0, ipcPo"]
[3.182056, "o", "rt=9867, storageInfo=lv=-57;cid=CID-5d885f87-f12d-453a-bd74-f156a1b4b789;nsid=1924983753;c=1611284134883), blocks: 13, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:25:37,151 INFO datanode.DataNode: Successfully sent block report 0xf6872ec5e8d6a4cc,  containing 1 storage report(s), of which we sent 1. The reports had 13 total blocks and used 1 RPC(s). This took 2 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:25:37,151 INFO datanode.DataNode: Got finalize command for block pool BP-51099006-172.31.0.6-1611284134883\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:25:52,676 INFO localizer.ResourceLocalizationService: Cache Size Before Clean: 0, Total Deleted: 0, Public Deleted: 0, Private Deleted: 0\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:25:52,922 INFO tracker.NMLogAggregationStatusTracker: Rolling over the cached log agg"]
[3.182072, "o", "regation status.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:25:53,559 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610699153559 and earlier in 0.0 seconds\u001b[K\r\n\u001b[36m\u001b[1mnodemanager exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[33mdatanode2 exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[34mnamenode exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[32mdatanode3 exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[36mdatanode exited with code 137\u001b(B\u001b[m\u001b[K\r\n\u001b[35mhistoryserver exited with code 137\u001b(B\u001b[m\u001b[K\r\n[root@k8snode1 docker-hadoop]# \u001b[K\r\n\u001b[30m\u001b[42m[1] 0:root@k8snode1:~/bigdata/docker-hadoop*                                                                                                                                            \"k8snode1\" 16:35 22-Jan-21\u001b(B\u001b[m\u001b[46;1H\u001b[1;46r\u001b[H\u001b[45;32H\u001b[?12l\u001b[?25h\r\u001b[K\u001b[1;45r\u001b[H\u001b[45d[root@k8snode1 docker-hadoop]# \u001b[1;46r\u001b[H\u001b[45;32H"]
[5.179083, "o", "\u001b[1;45r\u001b[H\u001b[45;32Hdocker-compose up\u001b[1;46r\u001b[H\u001b[45;49H"]
[6.494583, "o", "\u001b[1;45r\u001b[H\u001b[45d\n\u001b[1;46r\u001b[H\u001b[45d"]
[7.092296, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating network \"docker-hadoop_default\" with the default driver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[7.535986, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating volume \"docker-hadoop_hadoop_namenode\" with default driver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[7.602589, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating volume \"docker-hadoop_hadoop_datanode\" with default driver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[7.670838, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating volume \"docker-hadoop_hadoop_datanode2\" with default driver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[7.750919, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating volume \"docker-hadoop_hadoop_datanode3\" with default driver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.008467, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating historyserver ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.014778, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating nodemanager   ... \r\nCreating datanode2     ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.022601, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating namenode      ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.02414, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating datanode3     ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.040304, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating resourcemanager ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[8.054693, "o", "\u001b[1;45r\u001b[H\u001b[45dCreating datanode        ... \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[9.640417, "o", "\u001b[7A\u001b[K\u001b[1;45r\u001b[H\u001b[38dCreating historyserver   ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[9.693136, "o", "\u001b[2A\u001b[K\u001b[1;45r\u001b[H\u001b[43dCreating resourcemanager ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[9.885416, "o", "\u001b[6A\u001b[K\u001b[1;45r\u001b[H\u001b[39dCreating nodemanager     ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[9.88792, "o", "\u001b[5A\u001b[K\u001b[1;45r\u001b[H\u001b[40dCreating datanode2       ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[9.942027, "o", "\u001b[A\u001b[K\u001b[1;45r\u001b[H\u001b[44dCreating datanode        ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[9.983452, "o", "\u001b[3A\u001b[K\u001b[1;45r\u001b[H\u001b[42dCreating datanode3       ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[10.033691, "o", "\u001b[4A\u001b[K\u001b[1;45r\u001b[H\u001b[41dCreating namenode        ... \u001b[32mdone\u001b[1;46r\u001b[H\u001b[45d\u001b(B\u001b[m"]
[10.035629, "o", "\u001b[1;45r\u001b[H\u001b[45dAttaching to historyserver, resourcemanager, nodemanager, datanode2, datanode, datanode3, namenode\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.050708, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring core\r\n\u001b[36mdatanode           |\u001b[39m  - Setting hadoop.proxyuser.hue.hosts=*\r\n\u001b[36mdatanode           |\u001b[39m  - Setting fs.defaultFS=hdfs://namenode:9000\r\n\u001b[36mdatanode           |\u001b[39m  - Setting hadoop.http.staticuser.user=root\r\n\u001b[36mdatanode           |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[36mdatanode           |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\r\n\u001b[36mdatanode           |\u001b[39m Configuring hdfs\r\n\u001b[33mdatanode2          |\u001b[39m Configuring core\r\n\u001b[35mhistoryserver      |\u001b[39m Configuring core\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting hadoop.proxyuser.hue.hosts=*\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting fs.defaultFS=hdfs://namenode:9000\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting hadoop.http.staticuser.user=root\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\r\n\u001b[3"]
[10.050775, "o", "5mhistoryserver      |\u001b[39m Configuring hdfs\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting dfs.webhdfs.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting dfs.permissions.enabled=false\r\n\u001b[35mhistoryserver      |\u001b[39m Configuring yarn\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.timeline-service.leveldb-timeline-store.path=/hadoop/yarn/timeline\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[3"]
[10.050789, "o", "5mhistoryserver      |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting hadoop.proxyuser.hue.hosts=*\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting fs.defaultFS=hdfs://namenode:9000\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting hadoop.http.staticuser.user=root\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[33mdatanode2      "]
[10.050802, "o", "    |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\r\n\u001b[33mdatanode2          |\u001b[39m Configuring hdfs\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting dfs.datanode.data.dir=file:///hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45;7H\r"]
[10.052305, "o", "\u001b[?25l\u001b[H\u001b[33mdatanode2          |\u001b[39m  - Setting hadoop.http.staticuser.user=root\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m Configuring hdfs\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting dfs.datanode.data.dir=file:///hadoop/dfs/data\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m Configuring core\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting hadoop.proxyuser.hue.hosts=*\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting fs.defaultFS=hdfs://namenode:9000\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting hadoop.http.staticuser.user=root\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m Configuring core\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting hadoop.prox"]
[10.052541, "o", "yuser.hue.hosts=*\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting fs.defaultFS=hdfs://namenode:9000\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring core\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting hadoop.proxyuser.hue.hosts=*\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting fs.defaultFS=hdfs://namenode:9000\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting hadoop.http.staticuser.user=root\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting hadoop.proxyuser.hue.groups=*\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring hdfs\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting dfs.webhdfs.enabled=true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring core\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting hadoop.proxyuser.hue.hosts=*\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - S"]
[10.052565, "o", "etting fs.defaultFS=hdfs://namenode:9000\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting hadoop.http.staticuser.user=root\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting hadoop.proxyuser.hue.groups=*\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring hdfs\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting dfs.webhdfs.enabled=true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting dfs.permissions.enabled=false\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring yarn\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.timeline-service.enabled=true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\u001b[K\r\n\u001b[33m\u001b"]
[10.052578, "o", "[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.timeline-service.generic-application-history.enabled=true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.log-aggregation-enable=true\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\r\n\u001b[36mdatanode           |\u001b[39m  - Setting dfs.datanode.data.dir=file:///hadoop/dfs/data\r\n\u001b[34mname"]
[10.05259, "o", "node           |\u001b[39m  - Setting hadoop.http.staticuser.user=root\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.053502, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting dfs.permissions.enabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.056249, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting dfs.webhdfs.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.06196, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring hdfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.065831, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring yarn\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.069337, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.071594, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting dfs.permissions.enabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.072953, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting dfs.datanode.data.dir=file:///hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.075974, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[36mdatanode           |\u001b[39m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.081347, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[33mdatanode2          |\u001b[39m Configuring yarn\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.087174, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[34mnamenode           |\u001b[39m  - Setting hadoop.proxyuser.hue.groups=*\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.094371, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.097165, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[36mdatanode           |\u001b[39m  - Setting dfs.webhdfs.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.099155, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Configuring hdfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.108989, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.109306, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting dfs.webhdfs.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.111184, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.115333, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[34mnamenode           |\u001b[39m  - Setting dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[36mdatanode           |\u001b[39m  - Setting dfs.permissions.enabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.123535, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting dfs.permissions.enabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.127172, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.131022, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.134588, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting dfs.webhdfs.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.135406, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.139083, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.141335, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.142741, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.144233, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.146386, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.152402, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.152932, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting dfs.permissions.enabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.155094, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.158314, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.15906, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.159951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.165059, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.165428, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting dfs.namenode.name.dir=file:///hadoop/dfs/name\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.16991, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.171657, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.174937, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.17595, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Configuring yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.180103, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.18105, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.185494, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.18983, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.190405, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.193283, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.193868, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.timeline-service.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.194929, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.196133, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.20418, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.207972, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.208515, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.209543, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-vcores=4\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.210328, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.211311, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.217951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.219926, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.222151, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.22242, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.226932, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.229272, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.232214, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.232997, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.23599, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Configuring mapred\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.236433, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.239067, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.242648, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.243959, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.248874, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.251341, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.252334, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.25804, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.258367, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.259724, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.261044, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.267932, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.269924, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.273128, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.278947, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.280447, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.284913, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.286465, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.290953, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.2917, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.297933, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.298649, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.301803, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.303821, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.307819, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring kms\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.313916, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.315603, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.317546, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.318429, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring mapred\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.log-aggregation-enable=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.325455, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.328347, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.330743, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.33331, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.333599, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.333826, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.337205, "o", "\u001b[?25l\u001b[H\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m Configuring mapred\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.output.compress=true\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.nodemanager.resource.memory-mb=16384\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=98.5\u001b[K\r\n\u001b[3"]
[10.338477, "o", "2mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.resourcemanager.recovery.enabled=true\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.log-aggregation-enable=true\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B"]
[10.338516, "o", "\u001b[m  - Setting yarn.nodemanager.resource.cpu-vcores=8\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring httpfs\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.log-aggregation-enable=true\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.timeline-service.generic-application-history.enabled=true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring kms\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcema"]
[10.33853, "o", "nager.hostname=resourcemanager\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.timeline-service.hostname=historyserver\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring mapred\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.log-aggregation-enable=true\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.java.opts=-Xmx3072m\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\u001b[K\r\n\u001b[36m"]
[10.338542, "o", "\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[10.338689, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.hostname=resourcemanager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.341056, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.344708, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.345781, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.347114, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.351098, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.351916, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.35345, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.scheduler.capacity.root.default.maximum-allocation-mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.36287, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.365943, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.368218, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.framework.name=yarn\r\n\u001b[36mdatanode           |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.370608, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.aux-services=mapreduce_shuffle\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.376706, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.378567, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.381566, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.386643, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.386962, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.388415, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.resource_tracker.address=resourcemanager:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.39195, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.392488, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.395187, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.396966, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.398486, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.405651, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.413361, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.output.compress=true\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.timeline-service.hostname=historyserver\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.413865, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.41575, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.421715, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.42283, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.424092, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.425017, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.431397, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.43186, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.436928, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.43838, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.address=resourcemanager:8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.441856, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.443481, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.445506, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.446286, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.449817, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.454358, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapred.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.459697, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.463439, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.463936, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.465048, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.468541, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.470561, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.472929, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.474005, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.475019, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.476196, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.478978, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m Configuring mapred\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.486273, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring mapred\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.489664, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.49018, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.496415, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.497634, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.501836, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.50219, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.output.compress=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.508021, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.512505, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] check for namenode:9000...\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] namenode:9000 is not available yet\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.515118, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.518674, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.resource.memory-mb=16384\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.519357, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.522935, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.523812, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.527179, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.531919, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.resourcemanager.recovery.enabled=true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.537041, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.537832, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.537996, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.540335, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.544835, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.545572, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.54694, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.551915, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.552499, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.555633, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring mapred\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.556064, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Configuring httpfs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.558247, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring mapred\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.570659, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.573355, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[34mnamenode           |\u001b[39m Configuring kms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.57558, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.579212, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Configuring mapred\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.585858, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.590124, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.59325, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] check for namenode:9000...\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] namenode:9000 is not available yet\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.595792, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.597268, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.600545, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.606739, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.608117, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.609568, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.610963, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.618536, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.620464, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.62151, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.622984, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.625025, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.630187, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.631609, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.632269, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.632914, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.634182, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.637415, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.643922, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.646448, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.649917, "o", "\u001b[?25l\u001b[H\u001b[32mdatanode3          |\u001b[39m Configuring httpfs\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m Configuring kms\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.nodemanager.resource.cpu-vcores=8\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m Configuring kms\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m Configuring mapred\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m Configuring httpfs\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m Configuring mapred\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m Configuring kms\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m Configuring mapred\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.memory.mb=4096\u001b[K"]
[10.649964, "o", "\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] check for namenode:9000...\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] namenode:9000 is not available yet\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] try in 5s once again ...\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.java.opts=-Xmx3072m\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapred.child.java.opts=-Xmx4096m\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.reduce.java.opts=-Xmx6144m\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[36mda"]
[10.649976, "o", "tanode           |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.framework.name=yarn\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.reduce.memory.mb=8192\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.framework.name=yarn\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\u001b[K\r\n\u001b[33mdatanode2          |\u001b[3"]
[10.649989, "o", "9m Configuring for multihomed network\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Configuring for multihomed network\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.memory.mb=4096\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[10.652052, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapred.child.java.opts=-Xmx4096m\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.659919, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.660118, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.665936, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.reduce.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.670162, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.67817, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m Configuring for multihomed network\r\n\u001b[32mdatanode3          |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.framework.name=yarn\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.684385, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.688949, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m  - Setting mapreduce.map.env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.697597, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Configuring for multihomed network\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.713948, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m [1/100] check for namenode:9870...\r\n\u001b[33mdatanode2          |\u001b[39m [1/100] namenode:9870 is not available yet\r\n\u001b[33mdatanode2          |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.726482, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] check for namenode:9000...\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] namenode:9000 is not available yet\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.745683, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m [1/100] check for namenode:9870...\r\n\u001b[36mdatanode           |\u001b[39m [1/100] namenode:9870 is not available yet\r\n\u001b[36mdatanode           |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.751403, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m [1/100] check for namenode:9870...\r\n\u001b[32mdatanode3          |\u001b[39m [1/100] namenode:9870 is not available yet\r\n\u001b[32mdatanode3          |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[10.766761, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Formatting namenode name directory: /hadoop/dfs/name\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.271954, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:36,631 INFO namenode.NameNode: STARTUP_MSG: \r\n\u001b[34mnamenode           |\u001b[39m /************************************************************\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG: Starting NameNode\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   host = 52eaf9d41009/172.20.0.8\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   args = [-format, test]\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-"]
[11.272166, "o", "3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/"]
[11.27225, "o", "error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl"]
[11.272323, "o", "-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v201"]
[11.272392, "o", "80605.jar:/opt/hadoop\u001b[1;46r\u001b[H\u001b[45;61H\u001b[1;45r\u001b[H\u001b[45;61H-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/ha"]
[11.273918, "o", "doop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/co"]
[11.273988, "o", "mmon/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/"]
[11.274009, "o", "opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/op"]
[11.274025, "o", "t/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2\u001b[1;46r\u001b[H\u001b[45;166H\u001b[1;45r\u001b[H\u001b[45;166H.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/s"]
[11.27404, "o", "hare/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/h"]
[11.274055, "o", "adoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/"]
[11.27407, "o", "hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share"]
[11.274084, "o", "/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.\u001b[1;46r\u001b[H\u001b[45;61H\u001b[1;45r\u001b[H\u001b[45;61H7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/shar"]
[11.274097, "o", "e/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1."]
[11.27412, "o", "jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share"]
[11.274134, "o", "/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/ha"]
[11.274148, "o", "doop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/"]
[11.274346, "o", "\u001b[1;46r\u001b[H\u001b[45;166H\u001b[1;45r\u001b[H\u001b[45;166Hhadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[34mnamenode       "]
[11.274365, "o", "    |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[34mnamenode           |\u001b[39m ************************************************************/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.274418, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:36,639 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.356796, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:36,720 INFO namenode.NameNode: createNameNode [-format, test]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.70224, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m Formatting using clusterid: CID-99194ab9-4c95-4733-b1e9-676ea1054e0d\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.737609, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,103 INFO namenode.FSEditLog: Edit logging is async:true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.751044, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,117 INFO namenode.FSNamesystem: KeyProvider: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.751827, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,118 INFO namenode.FSNamesystem: fsLock is fair: true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.752374, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,119 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.757353, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,123 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,123 INFO namenode.FSNamesystem: supergroup          = supergroup\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,123 INFO namenode.FSNamesystem: isPermissionEnabled = false\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,124 INFO namenode.FSNamesystem: HA Enabled: false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.80139, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,167 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.823802, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,190 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,190 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.830449, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,194 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,194 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Jan 22 08:35:37\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,196 INFO util.GSet: Computing capacity for map BlocksMap\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,196 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.831385, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,197 INFO util.GSet: 2.0% max memory 2.6 GB = 52.7 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,197 INFO util.GSet: capacity      = 2^23 = 8388608 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.843933, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,209 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,209 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.851288, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,216 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,216 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,216 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,216 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,216 INFO blockmanagement.BlockManager: defaultReplication         = 3\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: maxReplication             = 512\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: minReplication             = 1\r\n\u001b[34mnamenode   "]
[11.851346, "o", "        |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,217 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.876601, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,242 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,242 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,242 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,242 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.888867, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,254 INFO util.GSet: Computing capacity for map INodeMap\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,254 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.889131, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,254 INFO util.GSet: 1.0% max memory 2.6 GB = 26.3 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,254 INFO util.GSet: capacity      = 2^22 = 4194304 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.895644, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,261 INFO namenode.FSDirectory: ACLs enabled? false\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,261 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,261 INFO namenode.FSDirectory: XAttrs enabled? true\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,261 INFO namenode.NameNode: Caching file names occurring more than 10 times\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.900309, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,266 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.901841, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,268 INFO snapshot.SnapshotManager: SkipList is disabled\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.906733, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,272 INFO util.GSet: Computing capacity for map cachedBlocks\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,272 INFO util.GSet: VM type       = 64-bit\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,273 INFO util.GSet: 0.25% max memory 2.6 GB = 6.6 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,273 INFO util.GSet: capacity      = 2^20 = 1048576 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.920655, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,284 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,284 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,284 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.921697, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,288 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,288 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.923601, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,290 INFO util.GSet: Computing capacity for map NameNodeRetryCache\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,290 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.924441, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,290 INFO util.GSet: 0.029999999329447746% max memory 2.6 GB = 809.5 KB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,290 INFO util.GSet: capacity      = 2^17 = 131072 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.955142, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,321 INFO namenode.FSImage: Allocated new BlockPoolId: BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[11.966277, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,332 INFO common.Storage: Storage directory /hadoop/dfs/name has been successfully formatted.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.000629, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,366 INFO namenode.FSImageFormatProtobuf: Saving image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.180935, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,546 INFO namenode.FSImageFormatProtobuf: Image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.190671, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,557 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.195234, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,561 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.195901, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:37,561 INFO namenode.NameNode: SHUTDOWN_MSG: \r\n\u001b[34mnamenode           |\u001b[39m /************************************************************\r\n\u001b[34mnamenode           |\u001b[39m SHUTDOWN_MSG: Shutting down NameNode at 52eaf9d41009/172.20.0.8\r\n\u001b[34mnamenode           |\u001b[39m ************************************************************/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.754699, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,112 INFO namenode.NameNode: STARTUP_MSG: \r\n\u001b[34mnamenode           |\u001b[39m /************************************************************\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG: Starting NameNode\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   host = 52eaf9d41009/172.20.0.8\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   args = []\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/h"]
[12.755162, "o", "adoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_a"]
[12.755407, "o", "nnotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/"]
[12.755598, "o", "opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/op"]
[12.755763, "o", "t/hadoop-3.2.1/share/\u001b[1;46r\u001b[H\u001b[45;74H\u001b[1;45r\u001b[H\u001b[45;74Hhadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/sh"]
[12.755944, "o", "are/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j"]
[12.756105, "o", "-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3."]
[12.756246, "o", "2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2."]
[12.756266, "o", "1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/op\u001b[1;46r\u001b[H\u001b[45;179H\u001b[1;45r\u001b[H\u001b[45;179Ht/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/h"]
[12.756277, "o", "dfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/s"]
[12.756296, "o", "hare/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib"]
[12.756367, "o", "\u001b[1;46r\u001b[H\u001b[45;152H\u001b[1;45r\u001b[H\u001b[45;152H/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pk"]
[12.756638, "o", "ix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1."]
[12.756776, "o", "jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/"]
[12.756919, "o", "hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on"]
[12.757058, "o", "-1.60.jar:/opt/hadoop-3.2.1/share/had\u001b[1;46r\u001b[H\u001b[45;47H\u001b[1;45r\u001b[H\u001b[45;47Hoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-"]
[12.757078, "o", "3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/shar"]
[12.75709, "o", "e/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[34mnamenode           |\u001b[39m ************************************************************/\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,120 INFO namenode.NameNode: registered"]
[12.757102, "o", " UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.837946, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,202 INFO namenode.NameNode: createNameNode []\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[12.935646, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,301 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.026972, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: NameNode metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.050607, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,416 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://namenode:9000\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,417 INFO namenode.NameNode: Clients should use namenode:9000 to access this namenode/service.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.162632, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,528 INFO util.JvmPauseMonitor: Starting JVM pause monitor\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.19154, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,558 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.204656, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,571 INFO util.log: Logging initialized @870ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.287565, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,652 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.289213, "o", "\u001b[?25l\u001b[Hb/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/sha"]
[13.289471, "o", "re/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-c"]
[13.289614, "o", "lient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop"]
[13.289751, "o", "/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-jso"]
[13.289871, "o", "n-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1"]
[13.2899, "o", ".jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/ya"]
[13.289912, "o", "rn/hadoop-yarn-submarine-3.2.1.jar\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m ************************************************************/\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,120 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,202 INFO namenode.NameNode: createNameNode []\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,301 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: NameNode metrics system star"]
[13.289924, "o", "ted\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,416 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://namenode:9000\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,417 INFO namenode.NameNode: Clients should use namenode:9000 to access this namenode/service.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,528 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,558 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,571 INFO util.log: Logging initialized @870ms\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,652 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[13.290794, "o", "\u001b[?25l\u001b[Hb/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/sha"]
[13.290965, "o", "re/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-c"]
[13.291084, "o", "lient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop"]
[13.291201, "o", "/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-jso"]
[13.291309, "o", "n-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1"]
[13.291328, "o", ".jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/ya"]
[13.291341, "o", "rn/hadoop-yarn-submarine-3.2.1.jar\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m ************************************************************/\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,120 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,202 INFO namenode.NameNode: createNameNode []\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,301 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,389 INFO impl.MetricsSystemImpl: NameNode metrics system star"]
[13.291353, "o", "ted\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,416 INFO namenode.NameNodeUtils: fs.defaultFS is hdfs://namenode:9000\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,417 INFO namenode.NameNode: Clients should use namenode:9000 to access this namenode/service.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,528 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,558 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,571 INFO util.log: Logging initialized @870ms\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,652 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[13.294746, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,661 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.303505, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,669 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.304688, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,671 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,671 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,671 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.325406, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,691 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,691 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.333529, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,699 INFO http.HttpServer2: Jetty bound to port 9870\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.334578, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,700 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.360037, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,726 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d0b7e3c{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.360482, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,726 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b741d6d{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.420231, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,785 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7486b455{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{/hdfs}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.43883, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,804 INFO server.AbstractConnector: Started ServerConnector@700fb871{HTTP/1.1,[http/1.1]}{0.0.0.0:9870}\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,804 INFO server.Server: Started @1104ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.590186, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,956 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,956 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.630349, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:38,996 INFO namenode.FSEditLog: Edit logging is async:true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.686502, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,052 INFO namenode.FSNamesystem: KeyProvider: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.687652, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,054 INFO namenode.FSNamesystem: fsLock is fair: true\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.687864, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,054 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.692472, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,059 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,059 INFO namenode.FSNamesystem: supergroup          = supergroup\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,059 INFO namenode.FSNamesystem: isPermissionEnabled = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.692589, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,059 INFO namenode.FSNamesystem: HA Enabled: false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.72482, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,091 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.732417, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,098 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,098 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.73564, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,102 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.736381, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,102 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Jan 22 08:35:39\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.737235, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,103 INFO util.GSet: Computing capacity for map BlocksMap\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,103 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.738554, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,105 INFO util.GSet: 2.0% max memory 2.6 GB = 52.7 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,105 INFO util.GSet: capacity      = 2^23 = 8388608 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.750907, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,117 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,117 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.757795, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,123 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,123 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,123 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,123 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.759023, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: defaultReplication         = 3\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: maxReplication             = 512\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: minReplication             = 1\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,124 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.782157, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,148 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,148 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,148 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.782698, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,148 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.794452, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,160 INFO util.GSet: Computing capacity for map INodeMap\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,160 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.795356, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,161 INFO util.GSet: 1.0% max memory 2.6 GB = 26.3 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,161 INFO util.GSet: capacity      = 2^22 = 4194304 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.808942, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,171 INFO namenode.FSDirectory: ACLs enabled? false\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,171 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,171 INFO namenode.FSDirectory: XAttrs enabled? true\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,171 INFO namenode.NameNode: Caching file names occurring more than 10 times\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.809864, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,176 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.812275, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,178 INFO snapshot.SnapshotManager: SkipList is disabled\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.816917, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,183 INFO util.GSet: Computing capacity for map cachedBlocks\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,183 INFO util.GSet: VM type       = 64-bit\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,183 INFO util.GSet: 0.25% max memory 2.6 GB = 6.6 MB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,183 INFO util.GSet: capacity      = 2^20 = 1048576 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.827475, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,193 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,193 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,193 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.83171, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,197 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,197 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.833009, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,199 INFO util.GSet: Computing capacity for map NameNodeRetryCache\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,199 INFO util.GSet: VM type       = 64-bit\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[13.833189, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,199 INFO util.GSet: 0.029999999329447746% max memory 2.6 GB = 809.5 KB\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,199 INFO util.GSet: capacity      = 2^17 = 131072 entries\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.143309, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,509 INFO common.Storage: Lock on /hadoop/dfs/name/in_use.lock acquired by nodename 415@52eaf9d41009\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.170023, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,536 INFO namenode.FileJournalManager: Recovering unfinalized segments in /hadoop/dfs/name/current\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,536 INFO namenode.FSImage: No edit log streams selected.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.170251, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,536 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/hadoop/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.235121, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,601 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.400036, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,766 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,766 INFO namenode.FSImage: Loaded image for txid 0 from /hadoop/dfs/name/current/fsimage_0000000000000000000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.404125, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,770 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.405283, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:39,771 INFO namenode.FSEditLog: Starting log segment at 1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.648947, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,014 INFO namenode.NameCache: initialized with 0 entries 0 lookups\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,014 INFO namenode.FSNamesystem: Finished loading FSImage in 811 msecs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.803144, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,169 INFO namenode.NameNode: RPC server is binding to 0.0.0.0:9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.831667, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,196 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.847272, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,213 INFO ipc.Server: Starting Socket Reader #1 for port 9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[14.991815, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,358 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.000545, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,366 INFO namenode.LeaseManager: Number of blocks under construction: 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.009496, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO blockmanagement.BlockManager: initializing replication queues\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.010055, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,376 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.024347, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Total number of blocks            = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of blocks being written    = 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.029035, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,395 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.030352, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,396 INFO ipc.Server: IPC Server listener on 9000: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.037436, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,403 INFO namenode.NameNode: NameNode RPC up at: namenode/172.20.0.8:9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.040072, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,406 INFO namenode.FSNamesystem: Starting services required for active state\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,406 INFO namenode.FSDirectory: Initializing quota with 4 thread(s)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.046766, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,413 INFO namenode.FSDirectory: Quota initialization completed in 6 milliseconds\r\n\u001b[34mnamenode           |\u001b[39m name space=1\r\n\u001b[34mnamenode           |\u001b[39m storage space=0\r\n\u001b[34mnamenode           |\u001b[39m storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.049982, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,416 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.516785, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [2/100] namenode:9000 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.518567, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.521493, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] check for datanode:9864...\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] datanode:9864 is not available yet\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.59572, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [2/100] namenode:9000 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.601115, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.605463, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] check for datanode:9864...\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] datanode:9864 is not available yet\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.722591, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m [2/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.73579, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [2/100] namenode:9000 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.739256, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.741476, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] check for datanode:9864...\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] datanode:9864 is not available yet\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.746938, "o", "\u001b[?25l\u001b[H\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,014 INFO namenode.NameCache: initialized with 0 entries 0 lookups\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,014 INFO namenode.FSNamesystem: Finished loading FSImage in 811 msecs\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,169 INFO namenode.NameNode: RPC server is binding to 0.0.0.0:9000\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,196 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,213 INFO ipc.Server: Starting Socket Reader #1 for port 9000\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,358 INFO namenode.FSNamesystem: Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,366 INFO namenode.LeaseManager: Number of blocks under const"]
[15.746989, "o", "ruction: 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO blockmanagement.BlockManager: initializing replication queues\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,375 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,376 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Total number of blocks            = 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of  over-rep"]
[15.747004, "o", "licated blocks = 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO blockmanagement.BlockManager: Number of blocks being written    = 0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,390 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,395 INFO ipc.Server: IPC Server Responder: starting\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,396 INFO ipc.Server: IPC Server listener on 9000: starting\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,403 INFO namenode.NameNode: NameNode RPC up at: namenode/172.20.0.8:9000\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,406 INFO namenode.FSNamesystem: Starting services required for active state\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,406 INFO namenode.FSDirectory: Initializing quota with 4 thread(s)\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,413 INFO namenode.FSD"]
[15.747015, "o", "irectory: Quota initialization completed in 6 milliseconds\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m name space=1\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m storage space=0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:40,416 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m [2/100] namenode:9000 is available.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] namenode:9870 is available.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] check for datanode:9864...\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] datanode:9864 is not available yet\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] try in 5s once again ...\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [2/100] namenode:9000 is available.\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] namenode:9870 is available.\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] check for datanode:9864...\u001b[K\r\n\u001b[33m\u001b[1"]
[15.747028, "o", "mresourcemanager    |\u001b(B\u001b[m [1/100] datanode:9864 is not available yet\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] try in 5s once again ...\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m [2/100] namenode:9870 is available.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [2/100] namenode:9000 is available.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] namenode:9870 is available.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] check for datanode:9864...\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] datanode:9864 is not available yet\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] try in 5s once again ...\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[15.748914, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m [2/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[15.756414, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m [2/100] namenode:9870 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[16.460817, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:41,809 INFO datanode.DataNode: STARTUP_MSG: \r\n\u001b[33mdatanode2          |\u001b[39m /************************************************************\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG: Starting DataNode\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG:   host = 1dba5e6f519f/172.20.0.4\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG:   args = []\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/h"]
[16.462741, "o", "adoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_a"]
[16.464489, "o", "nnotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/"]
[16.465262, "o", "opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/op"]
[16.465474, "o", "t/hadoop-3.2.1/share/\u001b[1;46r\u001b[H\u001b[45;74H\u001b[1;45r\u001b[H\u001b[45;74Hhadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/sh"]
[16.465644, "o", "are/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j"]
[16.465806, "o", "-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3."]
[16.465969, "o", "2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2."]
[16.466106, "o", "1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/op\u001b[1;46r\u001b[H\u001b[45;179H\u001b[1;45r\u001b[H\u001b[45;179Ht/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/h"]
[16.466237, "o", "dfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/s"]
[16.46637, "o", "hare/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb"]
[16.4665, "o", "-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/"]
[16.466628, "o", "lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/\u001b[1;46r\u001b[H\u001b[45;74H\u001b[1;45r\u001b[H\u001b[45;74Hhadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs"]
[16.466769, "o", "/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hado"]
[16.466797, "o", "op-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/"]
[16.466811, "o", "lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/had"]
[16.466823, "o", "oop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/h"]
[16.467149, "o", "\u001b[1;46r\u001b[H\u001b[45;179H\u001b[1;45r\u001b[H\u001b[45;179Hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[33mdatanode2          |\u001b[39m ST"]
[16.467173, "o", "ARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[33mdatanode2          |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[33mdatanode2          |\u001b[39m ************************************************************/\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:41,826 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[16.506059, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:41,863 INFO datanode.DataNode: STARTUP_MSG: \r\n\u001b[32mdatanode3          |\u001b[39m /************************************************************\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG: Starting DataNode\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   host = e4c34818b329/172.20.0.7\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   args = []\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/h"]
[16.508651, "o", "adoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_a"]
[16.50998, "o", "nnotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/"]
[16.510233, "o", "opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/op"]
[16.510395, "o", "t/hadoop-3.2.1/share/\u001b[1;46r\u001b[H\u001b[45;74H\u001b[1;45r\u001b[H\u001b[45;74Hhadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/sh"]
[16.510535, "o", "are/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j"]
[16.51067, "o", "-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3."]
[16.510803, "o", "2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2."]
[16.510823, "o", "1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/op\u001b[1;46r\u001b[H\u001b[45;179H\u001b[1;45r\u001b[H\u001b[45;179Ht/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/h"]
[16.510835, "o", "dfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/s"]
[16.510848, "o", "hare/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib"]
[16.511172, "o", "\u001b[1;46r\u001b[H\u001b[45;152H\u001b[1;45r\u001b[H\u001b[45;152H/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pk"]
[16.511326, "o", "ix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1."]
[16.511459, "o", "jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/"]
[16.511589, "o", "hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on"]
[16.511716, "o", "-1.60.jar:/opt/hadoop-3.2.1/share/had\u001b[1;46r\u001b[H\u001b[45;47H\u001b[1;45r\u001b[H\u001b[45;47Hoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-"]
[16.511735, "o", "3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/shar"]
[16.511747, "o", "e/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[32mdatanode3          |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[32mdatanode3          |\u001b[39m ************************************************************/\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:41,872 INFO datanode.DataNode: registered"]
[16.511759, "o", " UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[16.53813, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:41,888 INFO datanode.DataNode: STARTUP_MSG: \r\n\u001b[36mdatanode           |\u001b[39m /************************************************************\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG: Starting DataNode\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   host = 58ea8777cbd5/172.20.0.6\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   args = []\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/h"]
[16.539369, "o", "adoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_a"]
[16.539621, "o", "nnotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/"]
[16.53978, "o", "opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/op"]
[16.539932, "o", "t/hadoop-3.2.1/share/\u001b[1;46r\u001b[H\u001b[45;74H\u001b[1;45r\u001b[H\u001b[45;74Hhadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/sh"]
[16.54008, "o", "are/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j"]
[16.540215, "o", "-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3."]
[16.540354, "o", "2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2."]
[16.540374, "o", "1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/op\u001b[1;46r\u001b[H\u001b[45;179H\u001b[1;45r\u001b[H\u001b[45;179Ht/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/h"]
[16.540385, "o", "dfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/s"]
[16.540398, "o", "hare/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib"]
[16.540697, "o", "\u001b[1;46r\u001b[H\u001b[45;152H"]
[16.546998, "o", "\u001b[1;45r\u001b[H\u001b[45;152H/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/h"]
[16.547313, "o", "adoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2"]
[16.547471, "o", ".1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/ha"]
[16.547586, "o", "doop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hado"]
[16.547689, "o", "op-3.2.1/share/had\u001b[1;46r\u001b[H\u001b[45;47H\u001b[1;45r\u001b[H\u001b[45;47Hoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/"]
[16.547708, "o", "yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoo"]
[16.547721, "o", "p-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[36mdatanode           |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[36mdatanode           |\u001b[39m ************************************************************/\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:41,896 INFO datanode.DataNode: registered UNIX signal handle"]
[16.547733, "o", "rs for [TERM, HUP, INT]\r\n"]
[16.547995, "o", "\u001b[1;46r\u001b[H\u001b[45d"]
[17.072587, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,438 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.154231, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,519 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.222006, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,588 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.241956, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:42,604 INFO checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.302946, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,668 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.308744, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,667 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,667 INFO impl.MetricsSystemImpl: DataNode metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.358948, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:42,719 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.379951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,743 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,743 INFO impl.MetricsSystemImpl: DataNode metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.440045, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:42,802 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:42,802 INFO impl.MetricsSystemImpl: DataNode metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.553959, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,916 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.556941, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,918 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,922 INFO datanode.DataNode: Configured hostname is 58ea8777cbd5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.55893, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,923 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.56794, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,932 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.628957, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,987 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,989 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:42,989 INFO datanode.DataNode: Number threads for balancing is 50\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.633501, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,994 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:42,997 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.637398, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,001 INFO datanode.DataNode: Configured hostname is 1dba5e6f519f\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,001 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.644247, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,010 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.664257, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,028 INFO util.log: Logging initialized @1819ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.685621, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,050 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.692374, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,053 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.694432, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,057 INFO datanode.DataNode: Configured hostname is e4c34818b329\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,058 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.697121, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,061 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.75032, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,109 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.755049, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,112 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,112 INFO datanode.DataNode: Number threads for balancing is 50\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.758566, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,120 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,123 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.767321, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,125 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:9866\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,127 INFO datanode.DataNode: Balancing bandwidth is 10485760 bytes/s\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,127 INFO datanode.DataNode: Number threads for balancing is 50\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.770466, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,134 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.777426, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,136 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,136 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,136 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.798587, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,162 INFO http.HttpServer2: Jetty bound to port 36231\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,164 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.804375, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,169 INFO util.log: Logging initialized @1993ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.808854, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,174 INFO util.log: Logging initialized @1957ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.824112, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,190 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1a5b6f42{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.826262, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,190 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32115b28{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.900935, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,264 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@518caac3{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.906668, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,272 INFO server.AbstractConnector: Started ServerConnector@7cb502c{HTTP/1.1,[http/1.1]}{localhost:36231}\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,272 INFO server.Server: Started @2064ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.925162, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,288 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,291 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.931768, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,297 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.933598, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.948532, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,313 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.949955, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,316 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.957949, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,324 INFO http.HttpServer2: Jetty bound to port 46547\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.958794, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,325 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.96537, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,331 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.968155, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.988272, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,351 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1a5b6f42{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.989287, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,353 INFO http.HttpServer2: Jetty bound to port 46308\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,354 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[17.99794, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,361 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32115b28{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.021949, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,383 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32115b28{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,383 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6bb4dd34{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.077533, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,441 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4f74980d{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.082237, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,446 INFO server.AbstractConnector: Started ServerConnector@1b8a29df{HTTP/1.1,[http/1.1]}{localhost:46308}\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,446 INFO server.Server: Started @2271ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.085546, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,451 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@518caac3{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.090584, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,456 INFO server.AbstractConnector: Started ServerConnector@7cb502c{HTTP/1.1,[http/1.1]}{localhost:46547}\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,456 INFO server.Server: Started @2238ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.140694, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,507 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.148615, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,514 INFO datanode.DataNode: dnUserName = root\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,514 INFO datanode.DataNode: supergroup = supergroup\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.157101, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,523 INFO util.JvmPauseMonitor: Starting JVM pause monitor\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.217727, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,580 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.236083, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,602 INFO ipc.Server: Starting Socket Reader #1 for port 9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.323788, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,686 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.327203, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,693 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.332407, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,698 INFO datanode.DataNode: dnUserName = root\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,698 INFO datanode.DataNode: supergroup = supergroup\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.346487, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,710 INFO datanode.DataNode: dnUserName = root\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,710 INFO datanode.DataNode: supergroup = supergroup\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.353351, "o", "\u001b[?25l\u001b[H\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,264 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@518caac3{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,272 INFO server.AbstractConnector: Started ServerConnector@7cb502c{HTTP/1.1,[http/1.1]}{localhost:36231}\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,272 INFO server.Server: Started @2064ms\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,288 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,291 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,297 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 "]
[18.353424, "o", "INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,299 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,313 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,316 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,324 INFO http.HttpServer2: Jetty bound to port 46547\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-"]
[18.353442, "o", "22 08:35:43,325 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,331 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,334 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,351 INFO handler.ContextHandler: S"]
[18.353457, "o", "tarted o.e.j.s.ServletContextHandler@1a5b6f42{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,353 INFO http.HttpServer2: Jetty bound to port 46308\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,354 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,361 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32115b28{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,383 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@32115b28{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,383 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6bb4dd34{/static,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/static/,AVAILABLE}\u001b[K\r\n\u001b[33mdatanode2  "]
[18.353469, "o", "        |\u001b[39m 2021-01-22 08:35:43,441 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4f74980d{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,446 INFO server.AbstractConnector: Started ServerConnector@1b8a29df{HTTP/1.1,[http/1.1]}{localhost:46308}\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,446 INFO server.Server: Started @2271ms\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,451 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@518caac3{/,file:///opt/hadoop-3.2.1/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,456 INFO server.AbstractConnector: Started ServerConnector@7cb502c{HTTP/1.1,[http/1.1]}{localhost:46547}\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,456 INFO server.Server: Started @2238ms\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,507 INFO web.DatanodeHttpServer: Listening HTTP traffi"]
[18.35348, "o", "c on /0.0.0.0:9864\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,514 INFO datanode.DataNode: dnUserName = root\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,514 INFO datanode.DataNode: supergroup = supergroup\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,523 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,580 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,602 INFO ipc.Server: Starting Socket Reader #1 for port 9867\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,686 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,693 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,698 IN"]
[18.353492, "o", "FO datanode.DataNode: dnUserName = root\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,698 INFO datanode.DataNode: supergroup = supergroup\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,710 INFO datanode.DataNode: dnUserName = root\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,710 INFO datanode.DataNode: supergroup = supergroup\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,714 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,712 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[18.412368, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,772 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,771 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.425191, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,790 INFO ipc.Server: Starting Socket Reader #1 for port 9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.425649, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:43,791 INFO ipc.Server: Starting Socket Reader #1 for port 9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.476091, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,838 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.514558, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,878 INFO datanode.DataNode: Refresh request received for nameservices: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.523604, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,889 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.553242, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,915 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000 starting to offer service\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.5654, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,922 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.581149, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:43,940 INFO ipc.Server: IPC Server listener on 9867: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.636245, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:43,997 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.65204, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,015 INFO datanode.DataNode: Refresh request received for nameservices: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.659496, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,024 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.677424, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,041 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000 starting to offer service\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.701511, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,066 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.704537, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,067 INFO ipc.Server: IPC Server listener on 9867: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.72426, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,084 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:9867\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.75193, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,116 INFO datanode.DataNode: Refresh request received for nameservices: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.763438, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,124 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.777458, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,140 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000 starting to offer service\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.784991, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,151 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.790973, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,157 INFO ipc.Server: IPC Server listener on 9867: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.880195, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,245 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.881408, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,246 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.882091, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,247 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.882685, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,249 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.885909, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,252 INFO common.Storage: Lock on /hadoop/dfs/data/in_use.lock acquired by nodename 361@58ea8777cbd5\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.886776, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,253 INFO common.Storage: Lock on /hadoop/dfs/data/in_use.lock acquired by nodename 361@e4c34818b329\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.887498, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,253 INFO common.Storage: Storage directory with location [DISK]file:/hadoop/dfs/data is not formatted for namespace 1305365137. Formatting...\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,253 INFO common.Storage: Generated new storageID DS-b0188c6a-9c69-4c85-9354-5fa6467a703c for directory /hadoop/dfs/data \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.89073, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,254 INFO common.Storage: Storage directory with location [DISK]file:/hadoop/dfs/data is not formatted for namespace 1305365137. Formatting...\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,255 INFO common.Storage: Generated new storageID DS-2956a837-2eb2-400f-afd7-3e2da08ffe37 for directory /hadoop/dfs/data \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.908081, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,272 INFO common.Storage: Analyzing storage directories for bpid BP-823557088-172.20.0.8-1611304537313\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,272 INFO common.Storage: Locking is disabled for /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.915363, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,278 INFO common.Storage: Analyzing storage directories for bpid BP-823557088-172.20.0.8-1611304537313\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,278 INFO common.Storage: Locking is disabled for /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,279 INFO common.Storage: Block pool storage directory for location [DISK]file:/hadoop/dfs/data and block pool id BP-823557088-172.20.0.8-1611304537313 is not formatted. Formatting ...\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,279 INFO common.Storage: Formatting block pool BP-823557088-172.20.0.8-1611304537313 directory /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,273 INFO common.Storage: Block pool storage directory for location [DISK]file:/hadoop/dfs/data and block pool id BP-823557088-172.20.0.8-1611304537313 is no"]
[18.915426, "o", "t formatted. Formatting ...\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,273 INFO common.Storage: Formatting block pool BP-823557088-172.20.0.8-1611304537313 directory /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,275 INFO datanode.DataNode: Setting up storage: nsid=1305365137;bpid=BP-823557088-172.20.0.8-1611304537313;lv=-57;nsInfo=lv=-65;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313;bpid=BP-823557088-172.20.0.8-1611304537313;dnuuid=null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.918074, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,280 INFO datanode.DataNode: Generated and persisted new Datanode UUID 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.921099, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,283 INFO datanode.DataNode: Setting up storage: nsid=1305365137;bpid=BP-823557088-172.20.0.8-1611304537313;lv=-57;nsInfo=lv=-65;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313;bpid=BP-823557088-172.20.0.8-1611304537313;dnuuid=null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.921454, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,284 INFO datanode.DataNode: Generated and persisted new Datanode UUID 22a7e8e4-045b-4548-9410-eee02c01b84f\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.942586, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,308 INFO datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to namenode/172.20.0.8:9000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.944088, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,310 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.948244, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,314 INFO common.Storage: Lock on /hadoop/dfs/data/in_use.lock acquired by nodename 361@1dba5e6f519f\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.949066, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,315 INFO common.Storage: Storage directory with location [DISK]file:/hadoop/dfs/data is not formatted for namespace 1305365137. Formatting...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.949767, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,316 INFO common.Storage: Generated new storageID DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa for directory /hadoop/dfs/data \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.970812, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,336 INFO common.Storage: Analyzing storage directories for bpid BP-823557088-172.20.0.8-1611304537313\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,337 INFO common.Storage: Locking is disabled for /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.971649, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,337 INFO common.Storage: Block pool storage directory for location [DISK]file:/hadoop/dfs/data and block pool id BP-823557088-172.20.0.8-1611304537313 is not formatted. Formatting ...\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,337 INFO common.Storage: Formatting block pool BP-823557088-172.20.0.8-1611304537313 directory /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.975583, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,339 INFO datanode.DataNode: Setting up storage: nsid=1305365137;bpid=BP-823557088-172.20.0.8-1611304537313;lv=-57;nsInfo=lv=-65;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313;bpid=BP-823557088-172.20.0.8-1611304537313;dnuuid=null\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,339 INFO datanode.DataNode: Generated and persisted new Datanode UUID 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[18.999614, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,362 INFO impl.FsDatasetImpl: Added new volume: DS-b0188c6a-9c69-4c85-9354-5fa6467a703c\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,362 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/hadoop/dfs/data, StorageType: DISK\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.005159, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,367 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.00789, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,373 INFO checker.ThrottledAsyncChecker: Scheduling a check for /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.012645, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,374 INFO impl.FsDatasetImpl: Added new volume: DS-2956a837-2eb2-400f-afd7-3e2da08ffe37\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,375 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/hadoop/dfs/data, StorageType: DISK\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,378 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.017387, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,380 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.020387, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,382 INFO impl.FsDatasetImpl: Adding block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,382 INFO impl.FsDatasetImpl: Scanning block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.020758, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,385 INFO checker.ThrottledAsyncChecker: Scheduling a check for /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.034739, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,399 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.035399, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,400 INFO impl.FsDatasetImpl: Adding block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,401 INFO impl.FsDatasetImpl: Scanning block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.049657, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,414 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-823557088-172.20.0.8-1611304537313 on /hadoop/dfs/data: 32ms\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,414 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-823557088-172.20.0.8-1611304537313: 32ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.055361, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,417 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,417 INFO impl.BlockPoolSlice: Replica Cache file: /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current/replicas doesn't exist \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.061401, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,421 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data: 4ms\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,422 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-823557088-172.20.0.8-1611304537313: 6ms\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,424 INFO datanode.VolumeScanner: Now scanning bpid BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.066244, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,426 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-b0188c6a-9c69-4c85-9354-5fa6467a703c): finished scanning block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.074512, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,436 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-823557088-172.20.0.8-1611304537313 on /hadoop/dfs/data: 35ms\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,438 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-823557088-172.20.0.8-1611304537313: 38ms\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,439 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,439 INFO impl.BlockPoolSlice: Replica Cache file: /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current/replicas doesn't exist \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.079335, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,442 INFO impl.FsDatasetImpl: Added new volume: DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,442 INFO impl.FsDatasetImpl: Added volume - [DISK]file:/hadoop/dfs/data, StorageType: DISK\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.082442, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,443 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data: 4ms\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,444 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-823557088-172.20.0.8-1611304537313: 6ms\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,445 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.083812, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,446 INFO datanode.VolumeScanner: Now scanning bpid BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.086972, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,451 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-2956a837-2eb2-400f-afd7-3e2da08ffe37): finished scanning block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.090373, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,455 INFO checker.ThrottledAsyncChecker: Scheduling a check for /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.094413, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,460 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/22/21 12:12 PM with interval of 21600000ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.097217, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,456 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-b0188c6a-9c69-4c85-9354-5fa6467a703c): no suitable block pools found to scan.  Waiting 1814399967 ms.\u001b[45;1H\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.097909, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,464 INFO checker.DatasetVolumeChecker: Scheduled health check for volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.098486, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,461 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/22/21 8:37 AM with interval of 21600000ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.098938, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,465 INFO impl.FsDatasetImpl: Adding block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.099421, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,466 INFO impl.FsDatasetImpl: Scanning block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.10673, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,469 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-2956a837-2eb2-400f-afd7-3e2da08ffe37): no suitable block pools found to scan.  Waiting 1814399976 ms.\u001b[45;1H\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,472 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed) service to namenode/172.20.0.8:9000 beginning handshake with NN\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.115554, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,477 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 22a7e8e4-045b-4548-9410-eee02c01b84f) service to namenode/172.20.0.8:9000 beginning handshake with NN\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.152095, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,513 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.0.7:9866, datanodeUuid=22a7e8e4-045b-4548-9410-eee02c01b84f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 22a7e8e4-045b-4548-9410-eee02c01b84f\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,514 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.7:9866\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,514 INFO blockmanagement.BlockReportLeaseManager: Registered DN 22a7e8e4-045b-4548-9410-eee02c01b84f (172.20.0.7:9866).\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,511 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-823557088-172.20.0.8-1611304537313 on /hadoop/dfs/data: 45ms\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,511 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-823557088-172."]
[19.152161, "o", "20.0.8-1611304537313: 46ms\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,513 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,513 INFO impl.BlockPoolSlice: Replica Cache file: /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current/replicas doesn't exist \r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,514 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data: 1ms\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,515 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-823557088-172.20.0.8-1611304537313: 3ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.158545, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,520 INFO datanode.VolumeScanner: Now scanning bpid BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.159232, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,524 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa): finished scanning block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.16091, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.0.6:9866, datanodeUuid=4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.6:9866\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO blockmanagement.BlockReportLeaseManager: Registered DN 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed (172.20.0.6:9866).\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.162685, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 22a7e8e4-045b-4548-9410-eee02c01b84f) service to namenode/172.20.0.8:9000 successfully registered with NN\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: For namenode namenode/172.20.0.8:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.164148, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed) service to namenode/172.20.0.8:9000 successfully registered with NN\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: For namenode namenode/172.20.0.8:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.179253, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,540 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/22/21 8:37 AM with interval of 21600000ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.184503, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,545 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25) service to namenode/172.20.0.8:9000 beginning handshake with NN\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.24038, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,606 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa): no suitable block pools found to scan.  Waiting 1814399910 ms.\u001b[45;1H\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.268291, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,624 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b0188c6a-9c69-4c85-9354-5fa6467a703c for DN 172.20.0.6:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.27843, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.0.4:9866, datanodeUuid=3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.4:9866\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO blockmanagement.BlockReportLeaseManager: Registered DN 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25 (172.20.0.4:9866).\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,641 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2956a837-2eb2-400f-afd7-3e2da08ffe37 for DN 172.20.0.7:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.287209, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,645 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25) service to namenode/172.20.0.8:9000 successfully registered with NN\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.293481, "o", "\u001b[?25l\u001b[H\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,469 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-2956a837-2eb2-400f-afd7-3e2da08ffe37): no suitable block pools found to scan.  Waiting 1814399976 ms.\u001b[2;1H\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,472 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed) service to namenode/172.20.0.8:9000 beginning handshake with NN\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,477 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 22a7e8e4-045b-4548-9410-eee02c01b84f) service to namenode/172.20.0.8:9000 beginning handshake with NN\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,513 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.0.7:9866, datanodeUuid=22a7e8e4-045b-4548-9410-eee02c01b84f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b"]
[19.293809, "o", "1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 22a7e8e4-045b-4548-9410-eee02c01b84f\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,514 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.7:9866\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,514 INFO blockmanagement.BlockReportLeaseManager: Registered DN 22a7e8e4-045b-4548-9410-eee02c01b84f (172.20.0.7:9866).\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,511 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-823557088-172.20.0.8-1611304537313 on /hadoop/dfs/data: 45ms\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,511 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-823557088-172.20.0.8-1611304537313: 46ms\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,513 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data...\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,513 INFO impl.BlockPoo"]
[19.293965, "o", "lSlice: Replica Cache file: /hadoop/dfs/data/current/BP-823557088-172.20.0.8-1611304537313/current/replicas doesn't exist \u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,514 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data: 1ms\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,515 INFO impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-823557088-172.20.0.8-1611304537313: 3ms\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,520 INFO datanode.VolumeScanner: Now scanning bpid BP-823557088-172.20.0.8-1611304537313 on volume /hadoop/dfs/data\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,524 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa): finished scanning block pool BP-823557088-172.20.0.8-1611304537313\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegi"]
[19.294097, "o", "stration(172.20.0.6:9866, datanodeUuid=4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.6:9866\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,526 INFO blockmanagement.BlockReportLeaseManager: Registered DN 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed (172.20.0.6:9866).\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 22a7e8e4-045b-4548-9410-eee02c01b84f) service to namenode/172.20.0.8:9000 successfully registered with NN\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: For namenode namenode/172.20.0.8:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL "]
[19.294132, "o", "of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed) service to namenode/172.20.0.8:9000 successfully registered with NN\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,529 INFO datanode.DataNode: For namenode namenode/172.20.0.8:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,540 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/22/21 8:37 AM with interval of 21600000ms\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,545 INFO datanode.DataNode: Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25) service to namenode/172.20.0.8:9000 beginning handshake with NN\u001b[K\r\n\u001b[33mdatanode2   "]
[19.29415, "o", "       |\u001b[39m 2021-01-22 08:35:44,606 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa): no suitable block pools found to scan.  Waiting 1814399910 ms.\u001b[35;1H\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,624 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b0188c6a-9c69-4c85-9354-5fa6467a703c for DN 172.20.0.6:9866\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.20.0.4:9866, datanodeUuid=3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313) storage 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO net.NetworkTopology: Adding a new node: /default-rack/172.20.0.4:9866\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,640 INFO blockmanagement.BlockReportLeaseManager: Regi"]
[19.294178, "o", "stered DN 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25 (172.20.0.4:9866).\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,641 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-2956a837-2eb2-400f-afd7-3e2da08ffe37 for DN 172.20.0.7:9866\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,645 INFO datanode.DataNode: Block pool Block pool BP-823557088-172.20.0.8-1611304537313 (Datanode Uuid 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25) service to namenode/172.20.0.8:9000 successfully registered with NN\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,645 INFO datanode.DataNode: For namenode namenode/172.20.0.8:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[19.308575, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,670 INFO BlockStateChange: BLOCK* processReport 0x5578357fd3a30a04: Processing first storage report for DS-b0188c6a-9c69-4c85-9354-5fa6467a703c from datanode 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,671 INFO BlockStateChange: BLOCK* processReport 0x5578357fd3a30a04: from storage DS-b0188c6a-9c69-4c85-9354-5fa6467a703c node DatanodeRegistration(172.20.0.6:9866, datanodeUuid=4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,671 INFO BlockStateChange: BLOCK* processReport 0x3c6104dba4535e1f: Processing first storage report for DS-2956a837-2eb2-400f-afd7-3e2da08ffe37 from datanode 22a7e8e4-045b-4548-9410-eee02c01b84f\r\n\u001b[34mnamenode        "]
[19.30864, "o", "   |\u001b[39m 2021-01-22 08:35:44,671 INFO BlockStateChange: BLOCK* processReport 0x3c6104dba4535e1f: from storage DS-2956a837-2eb2-400f-afd7-3e2da08ffe37 node DatanodeRegistration(172.20.0.7:9866, datanodeUuid=22a7e8e4-045b-4548-9410-eee02c01b84f, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.337137, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,698 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa for DN 172.20.0.4:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.346385, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,711 INFO datanode.DataNode: Successfully sent block report 0x5578357fd3a30a04,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 58 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:44,711 INFO datanode.DataNode: Got finalize command for block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.354246, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,719 INFO datanode.DataNode: Successfully sent block report 0x3c6104dba4535e1f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 64 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:44,719 INFO datanode.DataNode: Got finalize command for block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.36132, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,727 INFO BlockStateChange: BLOCK* processReport 0x3987f3ae456bcaee: Processing first storage report for DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa from datanode 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:44,727 INFO BlockStateChange: BLOCK* processReport 0x3987f3ae456bcaee: from storage DS-d0cd862a-7fb9-4cb4-9a2c-ef85b4994ffa node DatanodeRegistration(172.20.0.4:9866, datanodeUuid=3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-99194ab9-4c95-4733-b1e9-676ea1054e0d;nsid=1305365137;c=1611304537313), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[19.375809, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,741 INFO datanode.DataNode: Successfully sent block report 0x3987f3ae456bcaee,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:44,742 INFO datanode.DataNode: Got finalize command for block pool BP-823557088-172.20.0.8-1611304537313\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.52799, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [2/100] datanode:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.531204, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] datanode2:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.541226, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] datanode3:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.544197, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [1/100] check for resourcemanager:8088...\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] resourcemanager:8088 is not available yet\r\n\u001b[35mhistoryserver      |\u001b[39m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.612769, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [2/100] datanode:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.61497, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] datanode2:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.620188, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m [1/100] datanode3:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.745212, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [2/100] datanode:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.747596, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] datanode2:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.752034, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] datanode3:9864 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[20.754078, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] check for resourcemanager:8088...\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] resourcemanager:8088 is not available yet\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [1/100] try in 5s once again ...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.117367, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,477 INFO resourcemanager.ResourceManager: STARTUP_MSG: \r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m /************************************************************\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG: Starting ResourceManager\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   host = f6da470e40de/172.20.0.3\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   args = []\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   version = 3.2.1\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/l"]
[21.11782, "o", "ib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar"]
[21.118067, "o", ":/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1"]
[21.118237, "o", "/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/"]
[21.118404, "o", "hadoop/common/lib/jetty-servlet-9.3.24.v20\u001b[1;46r\u001b[H\u001b[45;39H\u001b[1;45r\u001b[H\u001b[45;39H180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop"]
[21.118546, "o", "/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-"]
[21.118567, "o", "2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoo"]
[21.118579, "o", "p/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/ha"]
[21.118592, "o", "doop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/l"]
[21.118821, "o", "\u001b[1;46r\u001b[H\u001b[45;144H\u001b[1;45r\u001b[H\u001b[45;144Hib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-"]
[21.118993, "o", "asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/"]
[21.11902, "o", "jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/"]
[21.119032, "o", "hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4"]
[21.119044, "o", ".41.1.jar:/opt/hadoop-3.2.1/share/had"]
[21.12057, "o", "\u001b[1;46r\u001b[H\u001b[45;39H\u001b[1;45r\u001b[H\u001b[45;39Hoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2"]
[21.120733, "o", ".1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-na"]
[21.120754, "o", "tivetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2."]
[21.120766, "o", "1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/y"]
[21.120777, "o", "arn/hadoop-yarn-common-3.2.1.jar:/o"]
[21.121583, "o", "\u001b[1;46r\u001b[H\u001b[45;144H\u001b[1;45r\u001b[H\u001b[45;144Hpt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar"]
[21.121699, "o", ":/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-csv-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-client-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-common-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-3.2.1/share/ha"]
[21.121718, "o", "doop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m ************************************************************/\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,485 INFO resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.425164, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,791 INFO conf.Configuration: found resource core-site.xml at file:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.462898, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,829 INFO conf.Configuration: resource-types.xml not found\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,829 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.511766, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,878 INFO conf.Configuration: found resource yarn-site.xml at file:/opt/hadoop-3.2.1/etc/hadoop/yarn-site.xml\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.524029, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,890 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.559617, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,925 INFO security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.563281, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,929 INFO security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.567256, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,933 INFO security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.609154, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,975 INFO recovery.RMStateStoreFactory: Using RMStateStore implementation - class org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.610447, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,976 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.614768, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,981 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.615228, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:46,981 INFO resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.656151, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,022 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.event.EventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.65707, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,023 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.658354, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,024 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.659415, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,025 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.723418, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,088 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.778224, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,144 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,144 INFO impl.MetricsSystemImpl: ResourceManager metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.790603, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,157 INFO security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instantiated.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.79361, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,160 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.800231, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,166 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.801662, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,167 INFO resourcemanager.RMNMInfo: Registered RMNMInfo MBean\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.803003, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,168 INFO monitor.RMAppLifetimeMonitor: Application lifelime monitor interval set to 3000 ms.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.805981, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,172 INFO placement.MultiNodeSortingManager: Initializing NodeSortingService=MultiNodeSortingManager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.807557, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,174 INFO util.HostsFileReader: Refreshing hosts (include/exclude) list\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.812554, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,179 INFO conf.Configuration: found resource capacity-scheduler.xml at file:/opt/hadoop-3.2.1/etc/hadoop/capacity-scheduler.xml\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.82549, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,191 INFO scheduler.AbstractYarnScheduler: Minimum allocation = <memory:1024, vCores:1>\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,191 INFO scheduler.AbstractYarnScheduler: Maximum allocation = <memory:8192, vCores:4>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.8588, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,224 INFO capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,224 INFO capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.867035, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,233 INFO capacity.ParentQueue: root, capacity=1.0, absoluteCapacity=1.0, maxCapacity=1.0, absoluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m , reservationsContinueLooking=true, orderingPolicy=utilization, priority=0\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,233 INFO capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.887765, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,250 INFO capacity.LeafQueue: Initializing default\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m capacity = 1.0 [= (float) configuredCapacity / 100 ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m absoluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxCapacity = 1.0 [= configuredMaxCapacity ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m effectiveMinResource=<memory:0, vCores:0>\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m  , effectiveMaxResource=<memory:0, vCores:0>\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m userLimit = 100 [= configuredUserLimit ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m userLimitFactor = 1.0 [= configuredUserLimitFactor ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemAp"]
[21.887867, "o", "plications * absoluteCapacity)]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maximumAllocation = <memory:8192, vCores:4> [= configuredMaxAllocation ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m numContainers = 0 [= currentNumContainers ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m state = RUNNING [= configuredState ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= conf"]
[21.887903, "o", "iguredAcls ]\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m nodeLocalityDelay = 40\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m rackLocalityAdditionalDelay = -1\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m labels=*,\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m reservationsContinueLooking = true\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m preemptionDisabled = true\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m defaultAppPriorityPerQueue = 0\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m priority = 0\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxLifetime = -1 seconds\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m defaultLifetime = -1 seconds\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,250 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,250 INFO capacity.CapacitySchedu"]
[21.887921, "o", "lerQueueManager: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,251 INFO capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,252 INFO placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,253 INFO placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are \r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,253 INFO capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculato"]
[21.88794, "o", "r, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.890024, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,256 INFO conf.Configuration: dynamic-resources.xml not found\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[21.89338, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,258 INFO resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,258 INFO resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,259 INFO resourcemanager.AMSProcessingChain: Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain. \r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.03473, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,401 INFO impl.TimelineClientImpl: Timeline service address: historyserver:8188\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.352387, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanag"]
[22.352452, "o", "er    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716"]
[22.352466, "o", " INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Register"]
[22.352479, "o", "ing class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.42022, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,781 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.20.0.2:10200\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.496574, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,862 INFO util.log: Logging initialized @1776ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.56667, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,932 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.569287, "o", "\u001b[?25l\u001b[H\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m preemptionDisabled = true\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m defaultAppPriorityPerQueue = 0\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m priority = 0\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m maxLifetime = -1 seconds\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m defaultLifetime = -1 seconds\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,250 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0, effectiveMinResource=<memory:0, vCores:0> , effectiveMaxResource=<memory:0, vCores:0>\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,250 INFO capacity.CapacitySchedulerQueueManager: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,2"]
[22.569665, "o", "51 INFO capacity.CapacitySchedulerQueueManager: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,252 INFO placement.UserGroupMappingPlacementRule: Initialized queue mappings, override: false\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,253 INFO placement.MultiNodeSortingManager: MultiNode scheduling is 'false', and configured policies are \u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,253 INFO capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:4>>, asynchronousScheduling=false, asyncScheduleInterval=5ms,multiNodePlacementEnabled=false\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,256 INFO conf.Configuration: dynamic-resour"]
[22.569868, "o", "ces.xml not found\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,258 INFO resourcemanager.AMSProcessingChain: Initializing AMS Processing chain. Root Processor=[org.apache.hadoop.yarn.server.resourcemanager.DefaultAMSProcessor].\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,258 INFO resourcemanager.ApplicationMasterService: disabled placement handler will be used, all scheduling requests will be rejected.\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,259 INFO resourcemanager.AMSProcessingChain: Adding [org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.processor.DisabledPlacementProcessor] tp top of AMS Processing chain. \u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,401 INFO impl.TimelineClientImpl: Timeline service address: historyserver:8188\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$Sys"]
[22.570054, "o", "temMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for clas"]
[22.570077, "o", "s org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.ser"]
[22.570089, "o", "ver.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics.TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,716 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.metrics.AbstractSystemMetricsPublisher$SystemMetricsEventType for class org.apache.hadoop.yarn.server.resourcemanager.metrics."]
[22.570101, "o", "TimelineServiceV1Publisher$TimelineV1EventHandler\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,781 INFO client.AHSProxy: Connecting to Application History server at historyserver/172.20.0.2:10200\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,862 INFO util.log: Logging initialized @1776ms\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,932 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[22.571001, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,936 INFO http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.578016, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,944 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.582146, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFi"]
[22.582196, "o", "lter$StaticUserFilter) to context logs\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,947 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.583247, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,949 INFO http.HttpServer2: adding path spec: /cluster/*\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,949 INFO http.HttpServer2: adding path spec: /ws/*\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:47,949 INFO http.HttpServer2: adding path spec: /app/*\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.903252, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,269 INFO webapp.WebApps: Registered webapp guice modules\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.908327, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,274 INFO http.HttpServer2: Jetty bound to port 8088\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.9093, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,275 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.937035, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,303 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.94445, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,310 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.946038, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,312 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,312 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.947724, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,314 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4e76dac{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[22.948245, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:48,314 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d465e4b{/static,jar:file:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar!/webapps/static,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.093558, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver as a provider class\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.094664, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices as a root resource class\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.095457, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.134329, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.496951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:48 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.741342, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m Jan 22, 2021 8:35:49 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.760629, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,126 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@49ec6a9f{/,file:///tmp/jetty-0.0.0.0-8088-cluster-_-any-2188482613918610966.dir/webapp/,AVAILABLE}{/cluster}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.767581, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,132 INFO server.AbstractConnector: Started ServerConnector@25b52284{HTTP/1.1,[http/1.1]}{0.0.0.0:8088}\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,132 INFO server.Server: Started @3046ms\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,132 INFO webapp.WebApps: Web app cluster started at 8088\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.817422, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,182 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.824147, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,190 INFO ipc.Server: Starting Socket Reader #1 for port 8033\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.849798, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,216 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.852844, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,217 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,218 INFO ipc.Server: IPC Server listener on 8033: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[23.858553, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,222 INFO resourcemanager.ResourceManager: Transitioning to active state\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.577211, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,941 INFO resourcemanager.ResourceManager: Recovery started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.603526, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,967 INFO recovery.RMStateStore: Loaded RM state version info null\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:49,967 INFO recovery.RMStateStore: Storing RM state version info 1.3\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.702376, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,068 INFO hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=172.20.0.7:9866, 172.20.0.6:9866, 172.20.0.4:9866 for /rmstate/FSRMStateRoot/RMVersionNode.tmp\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.755222, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,120 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.869837, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,234 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001 src: /172.20.0.3:50862 dest: /172.20.0.7:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.888374, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,254 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.949188, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,315 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001 src: /172.20.0.7:33884 dest: /172.20.0.6:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[24.9673, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,333 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.029673, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,395 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001 src: /172.20.0.6:58940 dest: /172.20.0.4:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.116693, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,482 INFO DataNode.clienttrace: src: /172.20.0.6:58940, dest: /172.20.0.4:9866, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, duration(ns): 56314618\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,482 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.122827, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,487 INFO DataNode.clienttrace: src: /172.20.0.7:33884, dest: /172.20.0.6:9866, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, duration(ns): 57260592\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,488 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.4:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.134013, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,496 INFO DataNode.clienttrace: src: /172.20.0.3:50862, dest: /172.20.0.7:9866, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, duration(ns): 59448953\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,496 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.6:9866, 172.20.0.4:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.143079, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,509 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/RMVersionNode.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.320426, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,686 INFO hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=172.20.0.7:9866, 172.20.0.4:9866, 172.20.0.6:9866 for /rmstate/FSRMStateRoot/EpochNode.tmp\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.37846, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,744 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.379385, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,745 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002 src: /172.20.0.3:50868 dest: /172.20.0.7:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.380794, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,747 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.382264, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,748 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002 src: /172.20.0.7:37690 dest: /172.20.0.4:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.383788, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,750 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.400529, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,766 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002 src: /172.20.0.4:35934 dest: /172.20.0.6:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.412945, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,778 INFO DataNode.clienttrace: src: /172.20.0.4:35934, dest: /172.20.0.6:9866, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, duration(ns): 10011897\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,778 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.413632, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,780 INFO DataNode.clienttrace: src: /172.20.0.7:37690, dest: /172.20.0.4:9866, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, duration(ns): 9740105\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.414132, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,780 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.6:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.41715, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,783 INFO DataNode.clienttrace: src: /172.20.0.3:50868, dest: /172.20.0.7:9866, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, duration(ns): 13675352\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.417659, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,783 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.4:9866, 172.20.0.6:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.419626, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,786 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/EpochNode.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.49603, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,862 INFO recovery.FileSystemRMStateStore: Done loading applications from FS state store\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.50394, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,869 INFO security.RMDelegationTokenSecretManager: recovering RMDelegationTokenSecretManager.\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,869 INFO resourcemanager.RMAppManager: Recovering 0 applications\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,869 INFO resourcemanager.RMAppManager: Successfully recovered 0 out of 0 applications\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,869 INFO resourcemanager.ResourceManager: Recovery ended\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.513629, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,880 INFO recovery.RMStateStore: Updating AMRMToken\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.548339, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m [2/100] resourcemanager:8088 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.567276, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,932 INFO hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=172.20.0.6:9866, 172.20.0.4:9866, 172.20.0.7:9866 for /rmstate/FSRMStateRoot/AMRMTokenSecretManagerRoot/AMRMTokenSecretManagerNode.tmp\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.583431, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:50,949 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.587946, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,951 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003 src: /172.20.0.3:46130 dest: /172.20.0.6:9866\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,953 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.592788, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,959 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003 src: /172.20.0.6:58952 dest: /172.20.0.4:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.594388, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,960 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.596172, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,962 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003 src: /172.20.0.4:43946 dest: /172.20.0.7:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.608091, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,974 INFO DataNode.clienttrace: src: /172.20.0.4:43946, dest: /172.20.0.7:9866, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, duration(ns): 9079414\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:50,974 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.609369, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,975 INFO DataNode.clienttrace: src: /172.20.0.6:58952, dest: /172.20.0.4:9866, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, duration(ns): 10549000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.610723, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,976 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.7:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.612847, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,978 INFO DataNode.clienttrace: src: /172.20.0.3:46130, dest: /172.20.0.6:9866, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, duration(ns): 11946932\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,978 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.4:9866, 172.20.0.7:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.617076, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m DEPRECATED: Use of this command to start the timeline server is deprecated.\r\n\u001b[35mhistoryserver      |\u001b[39m Instead use the timelineserver command for it.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.61756, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,982 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/AMRMTokenSecretManagerRoot/AMRMTokenSecretManagerNode.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\r\n\u001b[35mhistoryserver      |\u001b[39m Starting the History Server anyway...\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.698517, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,064 INFO security.RMContainerTokenSecretManager: Rolling master-key for container-tokens\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.700928, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,065 INFO security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 1\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO recovery.RMStateStore: Storing RMDTMasterKey.\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,067 INFO recovery.FileSystemRMStateStore: Storing RMDelegationKey_1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.71324, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,078 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.0.4:9866, 172.20.0.6:9866, 172.20.0.7:9866 for /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_1.tmp\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.721149, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,083 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.721678, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,085 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.3:46294 dest: /172.20.0.4:9866\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,086 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.728966, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,091 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.4:35946 dest: /172.20.0.6:9866\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,095 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.73059, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,097 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.6:35600 dest: /172.20.0.7:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.747278, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,113 INFO DataNode.clienttrace: src: /172.20.0.6:35600, dest: /172.20.0.7:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, duration(ns): 7540419\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,113 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.749303, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,115 INFO DataNode.clienttrace: src: /172.20.0.4:35946, dest: /172.20.0.6:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, duration(ns): 16423815\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,115 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.7:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.751856, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,116 INFO DataNode.clienttrace: src: /172.20.0.3:46294, dest: /172.20.0.4:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, duration(ns): 15563213\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,117 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.6:9866, 172.20.0.7:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.759384, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [2/100] resourcemanager:8088 is available.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.763844, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,121 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_1.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.795341, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 2\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO recovery.RMStateStore: Storing RMDTMasterKey.\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO recovery.FileSystemRMStateStore: Storing RMDelegationKey_2\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.798679, "o", "\u001b[?25l\u001b[Hf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, duration(ns): 10549000\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:50,976 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.7:9866] terminating\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,978 INFO DataNode.clienttrace: src: /172.20.0.3:46130, dest: /172.20.0.6:9866, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, duration(ns): 11946932\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:50,978 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.4:9866, 172.20.0.7:9866] terminating\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m DEPRECATED: U"]
[25.798793, "o", "se of this command to start the timeline server is deprecated.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m Instead use the timelineserver command for it.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:50,982 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/AMRMTokenSecretManagerRoot/AMRMTokenSecretManagerNode.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m Starting the History Server anyway...\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,064 INFO security.RMContainerTokenSecretManager: Rolling master-key for container-tokens\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,065 INFO security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO security.RMDelegationTokenSecretManage"]
[25.798843, "o", "r: storing master key with keyID 1\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,066 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,067 INFO recovery.FileSystemRMStateStore: Storing RMDelegationKey_1\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,078 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=172.20.0.4:9866, 172.20.0.6:9866, 172.20.0.7:9866 for /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_1.tmp\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,083 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,085 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.3:46294 dest: /172.20.0.4:9866\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,086 INFO sasl.SaslDataTransferClient: SASL encryption trust check: l"]
[25.798898, "o", "ocalHostTrusted = false, remoteHostTrusted = false\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,091 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.4:35946 dest: /172.20.0.6:9866\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,095 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,097 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004 src: /172.20.0.6:35600 dest: /172.20.0.7:9866\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,113 INFO DataNode.clienttrace: src: /172.20.0.6:35600, dest: /172.20.0.7:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, duration(ns): 7540419\u001b[K\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,"]
[25.798913, "o", "113 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,115 INFO DataNode.clienttrace: src: /172.20.0.4:35946, dest: /172.20.0.6:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, duration(ns): 16423815\u001b[K\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,115 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.7:9866] terminating\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,116 INFO DataNode.clienttrace: src: /172.20.0.3:46294, dest: /172.20.0.4:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-161130"]
[25.798924, "o", "4537313:blk_1073741828_1004, duration(ns): 15563213\u001b[K\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,117 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.6:9866, 172.20.0.7:9866] terminating\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m [2/100] resourcemanager:8088 is available.\u001b[K\r\n\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,121 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_1.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B"]
[25.798936, "o", "\u001b[m 2021-01-22 08:35:51,157 INFO security.RMDelegationTokenSecretManager: storing master key with keyID 2\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO recovery.RMStateStore: Storing RMDTMasterKey.\u001b[K\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,157 INFO recovery.FileSystemRMStateStore: Storing RMDelegationKey_2\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h"]
[25.813918, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,175 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.827958, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,191 INFO hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=172.20.0.4:9866, 172.20.0.7:9866, 172.20.0.6:9866 for /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_2.tmp\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.831512, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,196 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.836696, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,200 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005 src: /172.20.0.3:46302 dest: /172.20.0.4:9866\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,201 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.848945, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,209 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005 src: /172.20.0.4:43958 dest: /172.20.0.7:9866\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,210 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.852934, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,215 INFO store.AbstractFSNodeStore: Created store directory :file:/tmp/hadoop-yarn-root/node-attribute\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.862257, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,219 INFO datanode.DataNode: Receiving BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005 src: /172.20.0.7:33914 dest: /172.20.0.6:9866\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.86416, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,228 INFO store.AbstractFSNodeStore: Finished write mirror at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.mirror\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,229 INFO store.AbstractFSNodeStore: Finished create editlog file at:file:/tmp/hadoop-yarn-root/node-attribute/nodeattribute.editlog\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.867111, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,231 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.nodelabels.NodeAttributesManagerImpl$ForwardingEventHandler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.867507, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,232 INFO placement.MultiNodeSortingManager: Starting NodeSortingService=MultiNodeSortingManager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.884291, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,247 INFO DataNode.clienttrace: src: /172.20.0.7:33914, dest: /172.20.0.6:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 4aebe1ce-e52c-44db-9ce7-4bfdce12ffed, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, duration(ns): 17035629\r\n\u001b[36mdatanode           |\u001b[39m 2021-01-22 08:35:51,247 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.887066, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,249 INFO DataNode.clienttrace: src: /172.20.0.4:43958, dest: /172.20.0.7:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 22a7e8e4-045b-4548-9410-eee02c01b84f, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, duration(ns): 22718847\r\n\u001b[32mdatanode3          |\u001b[39m 2021-01-22 08:35:51,249 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.20.0.6:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.888503, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,252 INFO DataNode.clienttrace: src: /172.20.0.3:46302, dest: /172.20.0.4:9866, bytes: 17, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_820940596_1, offset: 0, srvID: 3cf3d8c3-01a8-4504-841c-9b8b4c89aa25, blockid: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, duration(ns): 22825352\r\n\u001b[33mdatanode2          |\u001b[39m 2021-01-22 08:35:51,253 INFO datanode.DataNode: PacketResponder: BP-823557088-172.20.0.8-1611304537313:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[172.20.0.7:9866, 172.20.0.6:9866] terminating\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.895684, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,261 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[34mnamenode           |\u001b[39m 2021-01-22 08:35:51,259 INFO hdfs.StateChange: DIR* completeFile: /rmstate/FSRMStateRoot/RMDTSecretManagerRoot/DelegationKey_2.tmp is closed by DFSClient_NONMAPREDUCE_820940596_1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.900107, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,262 INFO ipc.Server: Starting Socket Reader #1 for port 8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.903735, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,270 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.905307, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,271 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,271 INFO ipc.Server: IPC Server listener on 8031: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.92276, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,288 INFO util.JvmPauseMonitor: Starting JVM pause monitor\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.945607, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,311 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.953564, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,318 INFO ipc.Server: Starting Socket Reader #1 for port 8030\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.961951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,328 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[25.967474, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,333 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,333 INFO ipc.Server: IPC Server listener on 8030: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.109951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,475 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 5000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.117215, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,480 INFO ipc.Server: Starting Socket Reader #1 for port 8032\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.124947, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:51,480 INFO applicationhistoryservice.ApplicationHistoryServer: STARTUP_MSG: \r\n\u001b[35mhistoryserver      |\u001b[39m /************************************************************\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG: Starting ApplicationHistoryServer\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   host = 43a262e1b91f/172.20.0.2\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   args = []\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   version = 3.2.1\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/comm"]
[26.125347, "o", "ons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/h"]
[26.125588, "o", "adoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/"]
[26.125766, "o", "hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/"]
[26.125932, "o", "common/lib/jetty-serv\u001b[1;46r\u001b[H\u001b[45;25H\u001b[1;45r\u001b[H\u001b[45;25Hlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common"]
[26.126083, "o", "/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.j"]
[26.12623, "o", "ar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/"]
[26.126372, "o", "lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hd"]
[26.126532, "o", "fs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share\u001b[1;46r\u001b[H\u001b[45;130H\u001b[1;45r\u001b[H\u001b[45;130H/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackso"]
[26.126667, "o", "n-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/"]
[26.126687, "o", "jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1"]
[26.126704, "o", ".jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0."]
[26.126715, "o", "52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3"]
[26.131021, "o", "\u001b[1;46r\u001b[H\u001b[45;25H\u001b[1;45r\u001b[H\u001b[45;25H.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/"]
[26.131575, "o", "opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapre"]
[26.131795, "o", "duce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/o"]
[26.13182, "o", "pt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/"]
[26.131833, "o", "share/hadoop/yarn/hadoop-yarn-commo\u001b[1;46r\u001b[H\u001b[45;130H\u001b[1;45r\u001b[H\u001b[45;130Hn-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/"]
[26.131845, "o", "share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[35mhistoryserver      |\u001b[39m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[35mhistoryserver      |\u001b[39m ************************************************************/\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,486 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:51,488 INFO applicationhistoryservice.ApplicationHistoryServer: registered UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.133675, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,494 INFO ipc.Server: IPC Server listener on 8032: starting\r\n\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,494 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.172633, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:51,536 INFO resourcemanager.ResourceManager: Transitioned to active state\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.401015, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:51,766 INFO nodemanager.NodeManager: STARTUP_MSG: \r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m /************************************************************\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG: Starting NodeManager\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   host = ad41cbb05597/172.20.0.5\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   args = []\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   version = 3.2.1\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.409326, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/o"]
[26.409803, "o", "pt/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop"]
[26.411438, "o", "/common/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-json"]
[26.412988, "o", "-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jsr30"]
[26.413875, "o", "5-3.0.0.jar:/opt/h\u001b[1;46r\u001b[H\u001b[45;95H\u001b[1;45r\u001b[H\u001b[45;95Hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1"]
[26.414089, "o", "/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/common/lib/zook"]
[26.414243, "o", "eeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/opt/hadoop-3"]
[26.414396, "o", ".2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop-3.2."]
[26.414528, "o", "1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:\u001b[1;46r\u001b[H\u001b[45;200H\u001b[1;45r\u001b[H\u001b[45;200H/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop-3.2."]
[26.414658, "o", "1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/hadoop-3.2"]
[26.414792, "o", ".1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1"]
[26.414934, "o", ".0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt"]
[26.415069, "o", "/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop-3.2.1/share/hadoo\u001b[1;46r\u001b[H\u001b[45;95H\u001b[1;45r\u001b[H\u001b[45;95Hp/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoo"]
[26.415197, "o", "p-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop-3.2.1/sha"]
[26.415217, "o", "re/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop-3.2.1/"]
[26.415229, "o", "share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yar"]
[26.415241, "o", "n-server-resourcemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/opt/hadoop-3.2.1/"]
[26.415528, "o", "\u001b[1;46r\u001b[H\u001b[45;200H\u001b[1;45r\u001b[H\u001b[45;200Hshare/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-client-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-common-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/hadoop-yarn-server-timelineservice-hbase-coprocessor-3.2.1.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelin"]
[26.415551, "o", "eservice/lib/commons-csv-1.0.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/commons-lang-2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-annotations-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-client-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-common-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/hbase-protocol-1.2.6.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/jcodings-1.0.13.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/joni-2.1.2.jar:/opt/hadoop-3.2.1/share/hadoop/yarn/timelineservice/lib/metrics-core-2.2.0.jar\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m STARTUP_MSG:   java = 1.8.0_232\r\n\u001b[36"]
[26.415563, "o", "m\u001b[1mnodemanager        |\u001b(B\u001b[m ************************************************************/\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.423406, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:51,789 INFO nodemanager.NodeManager: registered UNIX signal handlers for [TERM, HUP, INT]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.586011, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:51,951 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.647579, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,012 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,012 INFO impl.MetricsSystemImpl: ApplicationHistoryServer metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.759511, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,125 INFO timeline.LeveldbTimelineStore: Using leveldb path /hadoop/yarn/timeline/leveldb-timeline-store.ldb\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.798604, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,163 INFO timeline.LeveldbTimelineStore: Loaded timeline store version info 1.0\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,164 INFO timeline.LeveldbTimelineStore: Starting deletion thread with ttl 604800000 and cycle interval 300000\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.8875, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,253 INFO resourceplugin.ResourcePluginManager: No Resource plugins found from configuration!\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,253 INFO resourceplugin.ResourcePluginManager: Found Resource plugins from configuration: null\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.949287, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,315 INFO nodemanager.NodeManager: Node Manager health check script is not available or doesn't have execute permission, so not starting the node health script runner.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.991966, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,352 INFO timeline.LeveldbTimelineStore: Discarded 0 entities for timestamp 1610699752166 and earlier in 0.001 seconds\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,356 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,357 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.993404, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,358 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$LocalizationEventHandlerWrapper\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,358 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,359 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,359 INFO event.AsyncDispatche"]
[26.993461, "o", "r: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.994, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,360 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerSchedulerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.scheduler.ContainerScheduler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.995297, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,353 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,355 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,355 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[26.996012, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,362 INFO tracker.NMLogAggregationStatusTracker: the rolling interval seconds for the NodeManager Cached Log aggregation status is 600\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.013543, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,379 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,380 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.04313, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,409 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.056867, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,423 INFO ipc.Server: Starting Socket Reader #1 for port 10200\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.060502, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,426 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.082861, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,448 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationHistoryProtocolPB to the server\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.0833, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,449 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.083979, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,450 INFO ipc.Server: IPC Server listener on 10200: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.086475, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,453 INFO applicationhistoryservice.ApplicationHistoryClientService: Instantiated ApplicationHistoryClientService at historyserver/172.20.0.2:10200\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.087945, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,454 INFO util.JvmPauseMonitor: Starting JVM pause monitor\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.098908, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,464 INFO timeline.TimelineServerUtils: Filter initializers set for timeline service: org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.yarn.server.timeline.security.TimelineAuthenticationFilterInitializer\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.113278, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,479 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,479 INFO impl.MetricsSystemImpl: NodeManager metrics system started\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.122508, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,488 INFO util.log: Logging initialized @1488ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.140586, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,505 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.148458, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,514 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.1942, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,558 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@20140db9\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,560 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.195657, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,561 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadService\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,561 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,562 INFO localizer.ResourceLocalizationService: per directory file limit = 8192\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.200185, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,566 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.204625, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,569 INFO http.HttpRequestLog: Http request log for http.requests.applicationhistory is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.216801, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,576 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,578 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context applicationhistory\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,578 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,579 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.219203, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,580 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,585 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.220899, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,586 INFO http.HttpServer2: Added global filter 'Timeline Authentication Filter' (class=org.apache.hadoop.yarn.server.timeline.security.TimelineAuthenticationFilter)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.222617, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,589 INFO http.HttpServer2: adding path spec: /applicationhistory/*\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,589 INFO http.HttpServer2: adding path spec: /ws/*\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.239951, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,606 INFO containermanager.AuxServices: Adding auxiliary service mapreduce_shuffle, \"mapreduce_shuffle\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.265941, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,627 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@1807e3f6\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,627 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,628 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: Virtual memory check enabled: true\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true\r\n\u001b[1;46r\u001b[H\u001b[4"]
[27.266073, "o", "5d"]
[27.271933, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 WARN monitor.ContainersMonitorImpl: NodeManager configured with 16 G physical memory allocated to containers, which is more than 80% of the total physical memory available (11.6 G). Thrashing might happen.\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO logaggregation.LogAggregationService: rollingMonitorInterval is set as -1. The log rolling monitoring interval is disabled. The logs will be aggregated after this application is finished.\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO logaggregation.LogAggregationService: rollingMonitorInterval is set as -1. The logs will be aggregated every -1 seconds\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.284123, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,650 INFO conf.Configuration: resource-types.xml not found\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.287904, "o", "\u001b[?25l\u001b[H\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,453 INFO applicationhistoryservice.ApplicationHistoryClientService: Instantiated ApplicationHistoryClientService at historyserver/172.20.0.2:10200\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,454 INFO util.JvmPauseMonitor: Starting JVM pause monitor\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,464 INFO timeline.TimelineServerUtils: Filter initializers set for timeline service: org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.yarn.server.timeline.security.TimelineAuthenticationFilterInitializer\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,479 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,479 INFO impl.MetricsSystemImpl: NodeManager metrics system started\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,488 INFO util.log: Logging initialized @1488ms\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35"]
[27.288476, "o", ":52,505 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,514 INFO nodemanager.DirectoryCollection: Disk Validator 'basic' is loaded.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,558 INFO nodemanager.NodeResourceMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@20140db9\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,560 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,561 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.sharedcache.SharedCacheUploadEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localiz"]
[27.288779, "o", "er.sharedcache.SharedCacheUploadService\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,561 INFO containermanager.ContainerManagerImpl: AMRMProxyService is disabled\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,562 INFO localizer.ResourceLocalizationService: per directory file limit = 8192\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,566 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,569 INFO http.HttpRequestLog: Http request log for http.requests.applicationhistory is not defined\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,576 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,578 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context applica"]
[27.288933, "o", "tionhistory\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,578 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,579 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,580 INFO event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,585 INFO resources.ResourceHandlerModule: Using traffic control bandwidth handler\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,586 INFO http.HttpServer2: Added global filter 'Timeline Authentication Filter' ("]
[27.288955, "o", "class=org.apache.hadoop.yarn.server.timeline.security.TimelineAuthenticationFilter)\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,589 INFO http.HttpServer2: adding path spec: /applicationhistory/*\u001b[K\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:52,589 INFO http.HttpServer2: adding path spec: /ws/*\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,606 INFO containermanager.AuxServices: Adding auxiliary service mapreduce_shuffle, \"mapreduce_shuffle\"\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,627 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.ResourceCalculatorPlugin@1807e3f6\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,627 INFO monitor.ContainersMonitorImpl:  Using ResourceCalculatorProcessTree : null\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,628 INFO monitor.ContainersMonitorImpl: Physical memory check enabled: true\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO moni"]
[27.288967, "o", "tor.ContainersMonitorImpl: Virtual memory check enabled: true\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: Elastic memory control enabled: false\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: Strict memory control enabled: true\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,629 INFO monitor.ContainersMonitorImpl: ContainersMonitor enabled: true\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 WARN monitor.ContainersMonitorImpl: NodeManager configured with 16 G physical memory allocated to containers, which is more than 80% of the total physical memory available (11.6 G). Thrashing might happen.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO logaggregation.LogAggregationService: rollingMonitorInterval is set as -1. The log rolling monitoring interval is disabled. The logs will be aggregated after this application is finished.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager     "]
[27.28898, "o", "   |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO logaggregation.LogAggregationService: rollingMonitorInterval is set as -1. The logs will be aggregated every -1 seconds\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,632 INFO containermanager.ContainerManagerImpl: Not a recoverable state store. Nothing to recover.\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,650 INFO conf.Configuration: resource-types.xml not found\u001b[K\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,650 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[K\r\n\u001b[K\u001b[?12l\u001b[?25h\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,654 INFO conf.Configuration: node-resources.xml not found\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,654 INFO resource.ResourceUtils: Unable to find 'node-resources.xml'.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.289624, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,656 INFO nodemanager.NodeStatusUpdaterImpl: Nodemanager resources is set to: <memory:16384, vCores:8>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.294407, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,659 INFO nodemanager.NodeStatusUpdaterImpl: Initialized nodemanager with : physical-memory=16384 virtual-memory=34407 virtual-cores=8\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.34929, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,711 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.368234, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,732 INFO ipc.Server: Starting Socket Reader #1 for port 0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.539012, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,905 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.54099, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,906 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,907 INFO ipc.Server: IPC Server listener on 0: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.551125, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,916 INFO security.NMContainerTokenSecretManager: Updating node address : ad41cbb05597:33382\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.571462, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,936 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.573329, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,937 INFO ipc.Server: Starting Socket Reader #1 for port 8040\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.576241, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,940 INFO pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,940 INFO ipc.Server: IPC Server Responder: starting\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.59649, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,960 INFO ipc.Server: IPC Server listener on 8040: starting\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,961 INFO localizer.ResourceLocalizationService: Localizer started on port 8040\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.615186, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,981 INFO mapred.IndexCache: IndexCache created with max memory = 10485760\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.630232, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,995 INFO mapred.ShuffleHandler: mapreduce_shuffle listening on port 13562\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.634641, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,998 INFO containermanager.ContainerManagerImpl: ContainerManager started at ad41cbb05597/172.20.0.5:33382\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:52,998 INFO containermanager.ContainerManagerImpl: ContainerManager bound to 0.0.0.0/0.0.0.0:0\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.637573, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,003 INFO webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:8042\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.647233, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,012 INFO webapp.WebApps: Registered webapp guice modules\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.651223, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,014 INFO http.HttpServer2: Jetty bound to port 8188\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,015 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.697996, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,064 INFO delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.699058, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,065 INFO delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.704833, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,070 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1c852c0f{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.70677, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,073 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@13b3d178{/static,jar:file:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar!/webapps/static,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.711437, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,077 INFO util.log: Logging initialized @1814ms\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.777595, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,143 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.78252, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,147 INFO http.HttpRequestLog: Http request log for http.requests.nodemanager is not defined\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.793203, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,156 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,157 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,157 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,157 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,158 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context node\r\n\u001b[36m\u001b[1mnodem"]
[27.793283, "o", "anager        |\u001b(B\u001b[m 2021-01-22 08:35:53,158 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,158 INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.794338, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,160 INFO http.HttpServer2: adding path spec: /node/*\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,160 INFO http.HttpServer2: adding path spec: /ws/*\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.919529, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Registering org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider as a provider class\r\n\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Registering org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices as a root resource class\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.923939, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Registering org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices as a root resource class\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.926154, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\r\n\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.992965, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[27.995214, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Binding org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.128947, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,494 INFO webapp.WebApps: Registered webapp guice modules\r\n\u001b[1;46r\u001b[H\u001b[45d\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,495 INFO http.HttpServer2: Jetty bound to port 8042\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.130013, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,496 INFO server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.177022, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,543 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.180487, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,546 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2eced48b{/logs,file:///opt/hadoop-3.2.1/logs/,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.184537, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:53,549 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b7e96a{/static,jar:file:/opt/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar!/webapps/static,AVAILABLE}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.476772, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices as a root resource class\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Registering org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver as a provider class\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.486143, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.537193, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Binding org.apache.hadoop.yarn.server.applicationhistoryservice.webapp.AHSWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.555281, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[35mhistoryserver      |\u001b[39m INFO: Binding org.apache.hadoop.yarn.server.timeline.webapp.TimelineWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.57619, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:53 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.594169, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,954 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7ca0863b{/,file:///tmp/jetty-0.0.0.0-8188-applicationhistory-_-any-975565513567411472.dir/webapp/,AVAILABLE}{/applicationhistory}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.60043, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,958 INFO server.AbstractConnector: Started ServerConnector@4a55a6e8{HTTP/1.1,[http/1.1]}{0.0.0.0:8188}\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,959 INFO server.Server: Started @2959ms\r\n\u001b[35mhistoryserver      |\u001b[39m 2021-01-22 08:35:53,959 INFO applicationhistoryservice.ApplicationHistoryServer: Instantiating AHSWebApp at 8188\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[28.73649, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:54 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.017329, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m Jan 22, 2021 8:35:54 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m INFO: Binding org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices to GuiceManagedComponentProvider with the scope \"Singleton\"\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.048098, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,413 INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2f98635e{/,file:///tmp/jetty-0.0.0.0-8042-node-_-any-4332414736956827314.dir/webapp/,AVAILABLE}{/node}\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.053278, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,417 INFO server.AbstractConnector: Started ServerConnector@117bcfdc{HTTP/1.1,[http/1.1]}{0.0.0.0:8042}\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,417 INFO server.Server: Started @3154ms\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,417 INFO webapp.WebApps: Web app node started at 8042\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.057092, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,421 INFO nodemanager.NodeStatusUpdaterImpl: Node ID assigned is : ad41cbb05597:33382\r\n\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,423 INFO util.JvmPauseMonitor: Starting JVM pause monitor\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.06179, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,428 INFO client.RMProxy: Connecting to ResourceManager at resourcemanager/172.20.0.3:8031\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.104142, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,469 INFO nodemanager.NodeStatusUpdaterImpl: Sending out 0 NM container statuses: []\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.113831, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,479 INFO nodemanager.NodeStatusUpdaterImpl: Registering with RM using containers :[]\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.312137, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:54,677 INFO resourcemanager.ResourceTrackerService: NodeManager from node ad41cbb05597(cmPort: 33382 httpPort: 8042) registered with capability: <memory:16384, vCores:8>, assigned nodeId ad41cbb05597:33382\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.316734, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:54,682 INFO rmnode.RMNodeImpl: ad41cbb05597:33382 Node Transitioned from NEW to RUNNING\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.328666, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,694 INFO security.NMContainerTokenSecretManager: Rolling master-key for container-tokens, got key with id 1251290322\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.329673, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,695 INFO security.NMTokenSecretManagerInNM: Rolling master-key for container-tokens, got key with id 2125178641\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.330046, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[36m\u001b[1mnodemanager        |\u001b(B\u001b[m 2021-01-22 08:35:54,696 INFO nodemanager.NodeStatusUpdaterImpl: Registered with ResourceManager as ad41cbb05597:33382 with total resource of <memory:16384, vCores:8>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.343344, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:54,709 INFO capacity.CapacityScheduler: Added node ad41cbb05597:33382 clusterResource: <memory:16384, vCores:8>\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[29.372623, "o", "\u001b[1;45r\u001b[H\u001b[45d\u001b[33m\u001b[1mresourcemanager    |\u001b(B\u001b[m 2021-01-22 08:35:54,738 INFO resourcemanager.RMActiveServiceContext: Scheduler recovery is done. Start allocating new containers.\r\n\u001b[1;46r\u001b[H\u001b[45d"]
[48.005512, "o", "\u001b[?25l\r\n\u001b[30m\u001b[42m[1] 0:root@k8snode1:~/bigdata/docker-hadoop*                                                                                                                                            \"k8snode1\" 16:36 22-Jan-21\u001b(B\u001b[m\u001b[45;1H\u001b[?12l\u001b[?25h"]
[63.670428, "o", "\u001b[1;46r\u001b(B\u001b[m\u001b[?1l\u001b>\u001b[H\u001b[2J\u001b]112\u0007\u001b[?12l\u001b[?25h\u001b[?1000l\u001b[?1006l\u001b[?1005l\u001b[>4m\u001b[?1004l\u001b[?1049l"]
[63.670786, "o", "[detached]\r\n"]
[63.672384, "o", "[1]+  Done                    /topsec/topav_client/bin/nohup /usr/local/bin/linux_client >> /dev/null 2>&1\r\n\u001b]0;root@k8snode1:~/bigdata/docker-hadoop\u0007[root@k8snode1 docker-hadoop]# "]
[66.670118, "o", "exit\r\n"]
